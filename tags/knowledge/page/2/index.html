<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Knowledge | 我的博客</title><meta name=keywords content><meta name=description content="个人学习笔记博客"><meta name=author content="Pan Binghong"><link rel=canonical href=https://Pan-Binghong.github.io/daily-learning/tags/knowledge/><link crossorigin=anonymous href=/daily-learning/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://Pan-Binghong.github.io/daily-learning/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://Pan-Binghong.github.io/daily-learning/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://Pan-Binghong.github.io/daily-learning/favicon-32x32.png><link rel=apple-touch-icon href=https://Pan-Binghong.github.io/daily-learning/apple-touch-icon.png><link rel=mask-icon href=https://Pan-Binghong.github.io/daily-learning/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://Pan-Binghong.github.io/daily-learning/tags/knowledge/index.xml title=rss><link rel=alternate hreflang=en href=https://Pan-Binghong.github.io/daily-learning/tags/knowledge/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://Pan-Binghong.github.io/daily-learning/tags/knowledge/"><meta property="og:site_name" content="我的博客"><meta property="og:title" content="Knowledge"><meta property="og:description" content="个人学习笔记博客"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Knowledge"><meta name=twitter:description content="个人学习笔记博客"></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://Pan-Binghong.github.io/daily-learning/ accesskey=h title="我的博客 (Alt + H)">我的博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://Pan-Binghong.github.io/daily-learning/ title=首页><span>首页</span></a></li><li><a href=https://Pan-Binghong.github.io/daily-learning/ai/ title=AI><span>AI</span></a></li><li><a href=https://Pan-Binghong.github.io/daily-learning/knowledge/ title=知识库><span>知识库</span></a></li><li><a href=https://Pan-Binghong.github.io/daily-learning/backend/ title=后端><span>后端</span></a></li><li><a href=https://Pan-Binghong.github.io/daily-learning/devops/ title=DevOps><span>DevOps</span></a></li><li><a href=https://Pan-Binghong.github.io/daily-learning/other/ title=其他><span>其他</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Knowledge</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>大模型分布式训练_数据并行</h2></header><div class=entry-content><p>💡 记录并学习大模型分布式训练的方法以及原理等。
数据并行概述 数据并行是最简单的并行训练方法。在数据并行训练过程中，数据集被分割为n个部分，每个部分分配到一个GPU上。相当于按照:批次维度对训练进行并行化。同时每个GPU都将持有一个完整的模型副本，并在分配后的数据上进行训练。
数据并行（PyTorch DP） 缺点:
单进程多线程带来的问题：DataParallel使用单进程多线程进行实现的，方便了信息的交换，但受困于 GIL，会带来性能开销，速度很慢。而且，只能在单台服务器（单机多卡）上使用（不支持分布式）。同时，不能使用 Apex 进行混合精度训练。 效率问题，主卡性能和通信开销容易成为瓶颈，GPU 利用率通常很低：数据集需要先拷贝到主进程，然后再分片（split）到每个设备上；权重参数只在主卡（GPU0）上更新，需要每次迭代前向所有设备做一次同步；每次迭代的网络输出需要聚集到主卡（GPU0）上。因此，通信很快成为一个瓶颈。除此之外，这将导致主卡和其他卡之间，GPU利用率严重不均衡（比如：主卡使用了10G显存，而其他卡只使用了2G显存，batch size稍微设置大一点主卡的显存就OOM了）。 不支持模型并行，由于其本身的局限性，没办法与模型并行组合使用。 分布式数据并行 （PyTorch DDP） 计算过程:
首先将 rank=0 进程中的模型参数广播到进程组中的其他进程； 然后，每个 DDP 进程都会创建一个 local Reducer 来负责梯度同步。 在训练过程中，每个进程从磁盘加载 batch 数据，并将它们传递到其 GPU。每个 GPU 都有自己的前向过程，完成前向传播后，梯度在各个 GPUs 间进行 All-Reduce，每个 GPU 都收到其他 GPU 的梯度，从而可以独自进行反向传播和参数更新。 同时，每一层的梯度不依赖于前一层，所以梯度的 All-Reduce 和后向过程同时计算，以进一步缓解网络瓶颈。 在后向过程的最后，每个节点都得到了平均梯度，这样各个 GPU 中的模型参数保持同步 。 典型的数据并行实现方法:Pytorch DP/DDP 关键代码 单机数据并行的Pytorch代码实现 多机 DP和DDP的区别 DP是单进程多线程，只实用于单机。DDP是多进程实现，每个GPU表示一个进程，并且每个进程都是独立的Python解释器，DDP避免了GIL带来的性能开销。 更新参数方式 DDP支持模型并行，DP不支持。 补充ZeRO、FSDP 模型的训练运行占用的内存包含：模型权重，梯度值，激活值，数据(输入批次)和优化器状态。由于DDP在每个GPU上都copy了一份模型，因此DDP只能适用于能单卡放下模型时起到作用。以下是优化策略:
DeepSpeed(ZeRO) 激活检查点 全分片数据并行 Reference</p></div><footer class=entry-footer><span title='2024-12-30 07:01:00 +0000 UTC'>December 30, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 大模型分布式训练_数据并行" href=https://Pan-Binghong.github.io/daily-learning/knowledge/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83_%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>论文精度_HyDE</h2></header><div class=entry-content><p>💡 这里写创建该文章前的背景，心路历程。
记得常用分割线
https://python.langchain.com.cn/docs/templates/hyde
https://arxiv.org/pdf/2212.10496
引用链接用以下格式，比较好看~
Reference</p></div><footer class=entry-footer><span title='2024-11-28 07:59:00 +0000 UTC'>November 28, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 论文精度_HyDE" href=https://Pan-Binghong.github.io/daily-learning/knowledge/%E8%AE%BA%E6%96%87%E7%B2%BE%E5%BA%A6_hyde/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>论文精读_寻找RAG最优策略</h2></header><div class=entry-content><p>💡 这篇真的全是干货…论文的实验部分，我就不写了。看看就行。
相关工作|查询检索层面 确保大型语言模型（LLMs）如ChatGPT和LLaMA生成的回应准确性至关重要。然而，简单地增加模型大小并不能从根本上解决“幻觉”问题，这在知识密集型任务和专业领域尤为明显。检索增强生成（RAG）通过从外部知识库检索相关文档，为LLMs提供准确、实时、领域特定的上下文，以解决这些挑战。先前的工作通过查询和检索转换优化了RAG流程，提高了检索器的性能，并对检索器和生成器进行了微调。这些优化改善了输入查询、检索机制与生成过程之间的互动，确保了回应的准确性和相关性。
RAG工作流 在本节中，我们将详细介绍RAG工作流程的各个组件。针对每个模块，我们回顾常用的方法，并为我们的最终流程选择了默认和备选方法。
查询分类 并非所有的查询都需要通过检索增强，因为大型语言模型（LLMs）本身就具备一定的处理能力。尽管检索增强生成（RAG）可以提高信息的准确性并减少虚构内容，但频繁的检索可能会增加响应时间。因此，我们首先通过对查询进行分类来确定是否需要检索。需要检索的查询会经过RAG模块处理；其他则直接由LLMs处理。通常，在需要超出模型参数范围的知识时推荐使用检索。然而，检索的必要性根据任务的不同而有所变化。例如，一个训练至2023年的LLM可以处理“Sora是由OpenAI开发的”这一翻译请求而无需检索。相反，对于同一主题的介绍请求则需要检索来提供相关信息。
因此，我们建议按类型对任务进行分类，以确定查询是否需要检索。对于完全基于用户提供信息的任务，我们标记为“充分”，不需要检索；否则，我们标记为“不足”，可能需要检索。我们训练了一个分类器来自动化这一决策过程。
Chunking 将文档分块成更小的段落对于提高检索的准确性和避免在大型语言模型（LLMs）中出现长度问题至关重要。这个过程可以在不同的粒度级别上应用，比如令牌（token）、句子和语义级别。
令牌级别的分块很直接，但可能会分割句子，影响检索质量。 语义级别的分块利用大型语言模型来确定分割点，能保持上下文不变，但是耗时。 句子级别的分块在保留文本语义的同时，平衡了简单性和效率。 在这项研究中，我们使用句子级别的分块，平衡了简单性和语义保留。我们从四个维度考察了分块方法。 向量数据库存储着带有元数据的嵌入向量，通过各种索引和近似最近邻（ANN）方法，能够高效地检索与查询相关的文档。为了为我们的研究选择一个合适的向量数据库，我们基于四个关键标准对几个选项进行了评估：多种索引类型、支持十亿级别的向量、混合搜索以及云原生能力。这些标准因其对于灵活性、可扩展性以及在现代云基础设施中部署的便捷性的影响而被选中。多种索引类型提供了基于不同数据特性和用例优化搜索的灵活性。十亿级别的向量支持对于处理LLM应用中的大型数据集至关重要。混合搜索将向量搜索与传统关键词搜索结合起来，提高了检索准确性。最后，云原生能力确保了在云环境中的无缝集成、可扩展性和管理。
Retrieval方式 针对用户查询，检索模块从预建的语料库中选择与查询和文档的相似度最高的前k个相关文档。然后，生成模型使用这些文档来制定针对查询的适当响应。然而，原始查询由于表达不佳和缺乏语义信息，通常会表现不佳，这对检索过程产生了负面影响。为了解决这些问题，我们评估了三种查询转换方法，使用推荐的LLM-Embedder作为查询和文档编码器：
查询改写：查询改写通过改进查询来更好地匹配相关文档。受到Rewrite-Retrieve-Read框架的启发，我们促使一个LLM重写查询以提升性能。 查询分解：这种方法涉及到基于从原始查询中派生的子问题来检索文档，这比理解和处理更复杂的查询要困难。 伪文档生成：这种方法基于用户查询生成一个假想的文档，并使用假想答案的嵌入来检索相似文档。一个值得注意的实现是HyDE。 最近的研究表明结合基于词汇的搜索与向量搜索可以显著提高性能。在本研究中，我们使用BM25进行稀疏检索和Contriever，一个无监督对比编码器，进行密集检索。 Reranking 在最初的检索之后，将采用重排序阶段来提高检索到的文档的相关性，确保最相关的信息出现在列表的顶部。这一阶段采用更精确、耗时更长的方法有效地重新排序文档，增加查询与排名最高的文档之间的相似度。
在我们的重排序模块中，我们考虑了两种方法：DLM重排序和TILDE重排序。DLM重排序采用分类方法，而TILDE重排序则侧重于查询可能性。这些方法分别优先考虑性能和效率。
DLM重排方法：这种方法利用深度语言模型（DLMs）进行重排。这些模型被微调用以将文档与查询的相关性分类为“真”或“假”。在微调过程中，模型通过将查询和文档输入连接起来，并根据相关性进行标记来进行训练。在推理时，文档根据“真”标记的概率进行排名。 TILDE重排：TILDE通过预测模型词汇表中的各个词项的概率来独立计算每个查询词项的可能性。通过对查询词项的预计算对数概率求和，为文档打分，从而在推理时快速重排。TILDEv2通过仅索引文档中存在的词项，使用NCE损失，并扩展文档，从而提高效率并减小索引大小。 我们的实验是在MS MARCO Passage排名数据集上进行的，这是一个大规模的机器阅读理解数据集。我们遵循并对PyGaggle和TILDE提供的实现进行了修改，使用了模型monoT5、monoBERT、RankLLaMA和TILDEv2。重排结果显示在表中。我们推荐monoT5作为一种综合性的方法，平衡了性能和效率。RankLLaMA适合于实现最佳性能，而TILDEv2是在固定集合上获得最快体验的理想选择。实验设置和结果的详细信息在附录中呈现。 文档重组 文档重组后续过程的表现，比如LLM响应生成，可能会受到提供文档的顺序影响。为了解决这个问题，在重新排名之后的工作流程中，我们加入了一个紧凑的重组模块，包含三种重组方法：“前向”、“反向”和“两侧”。“前向”方法通过降序重新排名阶段的相关性得分来重组文档，而“反向”则按升序排列它们。对于LLM，当相关信息放在输入的头部或尾部时，可以达到最佳性能，我们也加入了“两侧”选项。
Reference</p></div><footer class=entry-footer><span title='2024-11-28 07:08:00 +0000 UTC'>November 28, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 论文精读_寻找RAG最优策略" href=https://Pan-Binghong.github.io/daily-learning/knowledge/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB_%E5%AF%BB%E6%89%BErag%E6%9C%80%E4%BC%98%E7%AD%96%E7%95%A5/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>什么是Unicode字符集以及UTF8编码</h2></header><div class=entry-content><p>两者的关系 Unicode 是字符集的规范，它定义了字符与码点的对应关系，但并不涉及具体的编码实现。 UTF-8 是一种编码方案，将 Unicode 码点转换为适合计算机存储和传输的字节序列。 类比： Unicode 是一本“词典”，记录了每个字符的编号。 UTF-8 是“包装方式”，将这些编号转换为计算机能处理的格式。 拓展 Python代码帮助理解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # Unicode字符集示例 # 1. 基本的Unicode字符串 simple_string = "你好，世界！" print("1. 基本Unicode字符串:", simple_string) # 2. Unicode编码和解码 # 使用encode()将字符串编码为bytes encoded_string = simple_string.encode('utf-8') print("2. UTF-8编码后:", encoded_string) # 使用decode()将bytes解码回字符串 decoded_string = encoded_string.decode('utf-8') print("2. 解码回字符串:", decoded_string) # 3. Unicode转义序列 unicode_escape = "\u4F60\u597D" # "你好"的Unicode编码 print("3. Unicode转义序列:", unicode_escape) # 4. 处理不同的Unicode字符 special_chars = "🌟✨🎈🎉" # emoji表情 print("4. 特殊Unicode字符(emoji):", special_chars) # 5. 获取字符的Unicode编码点 char = "中" unicode_point = ord(char) print(f"5. '中'的Unicode码点: {unicode_point} (十进制)") print(f"5. '中'的Unicode码点: {hex(unicode_point)} (十六进制)") # 6. 从编码点创建字符 code_point = 0x4E2D # "中"的Unicode编码点 character = chr(code_point) print(f"6. 从编码点创建字符: {character}") 结果展示 References
...</p></div><footer class=entry-footer><span title='2024-11-25 01:30:00 +0000 UTC'>November 25, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 什么是Unicode字符集以及UTF8编码" href=https://Pan-Binghong.github.io/daily-learning/knowledge/%E4%BB%80%E4%B9%88%E6%98%AFunicode%E5%AD%97%E7%AC%A6%E9%9B%86%E4%BB%A5%E5%8F%8Autf8%E7%BC%96%E7%A0%81/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>什么是ASCII字符集</h2></header><div class=entry-content><p>💡 （American Standard Code for Information Interchange，美国信息交换标准代码）是计算机科学中的一种字符编码标准，用于表示文本数据。它为每个字符分配了一个唯一的数字编码，主要用于通信设备、计算机和其他电子设备之间的数据交换。
特点 范围： ASCII码使用7位二进制数（0到127）来表示字符，共定义了128个字符。00000001
数字：0-9 （ASCII值为48到57） 大写字母：A-Z （ASCII值为65到90） 小写字母：a-z （ASCII值为97到122） 特殊符号：如空格（32）、换行（10）、感叹号（33）、@（64）等。 控制字符：如回车（13）、换页（12）、删除（127）等。 详细一览 为什么只使用7位？ 早期计算机内存和存储资源有限，使用7位编码能够节省空间，同时满足当时的英文字符需求（128个字符足够表示所有常用符号和字母）。后来为了支持更多语言和符号，扩展了8位（256个字符）的编码，称为扩展ASCII。
Python实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def show_ascii_info(char): """ 显示字符对应的ASCII码信息 参数: char - 要查看的字符 返回: 包含ASCII信息的字符串 """ ascii_value = ord(char) binary_value = bin(ascii_value)[2:].zfill(8) # 转换为8位二进制 hex_value = hex(ascii_value)[2:].upper() # 转换为16进制 return f""" 字符 '{char}' 的ASCII信息: - ASCII码值: {ascii_value} - 二进制: {binary_value} - 十六进制: {hex_value} """ def show_common_ascii(): """显示一些常见的ASCII码范围""" print("\n常见ASCII码范围:") print("1. 数字 (48-57):") for i in range(48, 58): print(f"{chr(i)} = {i}") print("\n2. 大写字母 (65-90):") for i in range(65, 91): print(f"{chr(i)} = {i}") print("\n3. 小写字母 (97-122):") for i in range(97, 123): print(f"{chr(i)} = {i}") def main(): print("ASCII码学习程序") print("-" * 30) # 测试一些字符 test_chars = ['A', '1', 'z', '@', '中'] # 注意：'中'是Unicode字符 for char in test_chars: try: print(show_ascii_info(char)) except ValueError: print(f"注意: '{char}' 不是ASCII字符") # 显示常见ASCII码范围 show_common_ascii() # 交互式测试 while True: user_input = input("\n请输入一个字符(按回车退出): ") if not user_input: break try: print(show_ascii_info(user_input[0])) except ValueError: print(f"注意: '{user_input[0]}' 不是ASCII字符") if __name__ == "__main__": main() Reference
...</p></div><footer class=entry-footer><span title='2024-11-24 14:36:00 +0000 UTC'>November 24, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 什么是ASCII字符集" href=https://Pan-Binghong.github.io/daily-learning/knowledge/%E4%BB%80%E4%B9%88%E6%98%AFascii%E5%AD%97%E7%AC%A6%E9%9B%86/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>什么是Base64</h2></header><div class=entry-content><p>💡 记录一下Base64原理，优点之类的。
概念解释 Base64是一种基于64个可打印字符来表示二进制数据的表示方法。
常用于在不支持二进制数据的场合（如电子邮件、URL等）传输二进制数据。
应用场景 电子邮件中嵌入图片或者其他二进制文件。 Web开发内，将小图片编码为Base64字符串，减少HTTP请求次数。 在编程语言内，用于对字符串进行编码和解码。 关于Base64编码格式的经典问题 Base64编码优缺点 Base64编码后的字符串为什么会变长？ Base64编码后的字符串末尾为什么会出现“=”号？ Base64 Alphabet Python代码实现Base64编码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def base(string:str)->str: oldstr = '' newstr = [] base = '' base64_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P','Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v','w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '/'] #把原始字符串转换为二进制，用bin转换后是0b开头的，所以把b替换了，首位补0补齐8位 for i in string: oldstr += '{:08}'.format(int(str(bin(ord(i))).replace('0b', ''))) #把转换好的二进制按照6位一组分好，最后一组不足6位的后面补0 for j in range(0, len(oldstr), 6): newstr.append('{:&lt;06}'.format(oldstr[j:j + 6])) #在base_list中找到对应的字符，拼接 for l in range(len(newstr)): base += base64_list[int(newstr[l], 2)] #判断base字符结尾补几个‘=’ if len(string) % 3 == 1: base += '==' elif len(string) % 3 == 2: base += '=' return base Base64包实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 import base64 from pathlib import Path def base64_converter(text, mode='encode', output_path=None): """ 处理base64编解码的函数 参数: text (str/Path/bytes): 要处理的文本、图片文件路径或base64编码的bytes mode (str): 'encode' 用于编码，'decode' 用于解码 output_path (str/Path): 解码图片时的保存路径，默认为None """ # 处理文本字符串 if isinstance(text, str) and not Path(text).is_file(): if mode == 'encode': text_bytes = text.encode('utf-8') encoded = base64.b64encode(text_bytes) return encoded.decode('utf-8') else: decoded = base64.b64decode(text) return decoded.decode('utf-8') # 处理图片文件或bytes数据 if mode == 'encode': if isinstance(text, bytes): return base64.b64encode(text) with open(text, 'rb') as image_file: return base64.b64encode(image_file.read()) else: # 使用指定的输出路径或当前目录 save_path = Path(output_path) if output_path else Path.cwd() / "decoded_image.png" save_path.parent.mkdir(parents=True, exist_ok=True) # 解码并保存图片 if isinstance(text, bytes): image_data = base64.b64decode(text) else: image_data = base64.b64decode(text.encode('ascii') if isinstance(text, str) else text) with open(save_path, 'wb') as image_file: image_file.write(image_data) return f"图片已保存到: {save_path.absolute()}" if __name__ == "__main__": # 文本编解码测试 result = base64_converter("Hello, World!", mode='encode') print("编码结果:", result) decoded = base64_converter(result, mode='decode') print("解码结果:", decoded) # 图片编解码测试 test_image_path = "test.png" if Path(test_image_path).exists(): # 编码图片 image_base64 = base64_converter(test_image_path, mode='encode') # 解码到输出文件 result = base64_converter(image_base64, mode='decode', output_path="decoded_test.png") print(result) ...</p></div><footer class=entry-footer><span title='2024-11-24 02:53:00 +0000 UTC'>November 24, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 什么是Base64" href=https://Pan-Binghong.github.io/daily-learning/knowledge/%E4%BB%80%E4%B9%88%E6%98%AFbase64/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>国内外算力卡调研</h2></header><div class=entry-content><p>💡 emmm…涉及敏感信息。。。这篇就不发布出来了。有需要可以单独联系我。</p></div><footer class=entry-footer><span title='2024-11-18 07:21:00 +0000 UTC'>November 18, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 国内外算力卡调研" href=https://Pan-Binghong.github.io/daily-learning/knowledge/%E5%9B%BD%E5%86%85%E5%A4%96%E7%AE%97%E5%8A%9B%E5%8D%A1%E8%B0%83%E7%A0%94/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>什么是云算、超算、智算、通算</h2></header><div class=entry-content><p>💡 互联网专业名词解释, 大部分从IBM官网搬运。
什么是云计算? 云计算就是指通过互联网以服务的形式按需提供计算资源（例如存储和基础设施）。这样，个人和企业就无需自行管理物理资源，而且只需为实际使用的资源付费。
Reference
什么是超级计算? 超级计算是一种高性能计算形式，使用功能强大的计算机”超级计算机”执行确定或计算，减少总求解时间。
Reference
什么是高性能计算 (HPC)？ 高性能计算 (HPC) 是一种利用强大处理器集群并行处理海量多维数据集（也称为大数据）并以极高速度解决复杂问题的技术。
Reference
什么是边缘计算？ 边缘计算是一种分布式计算框架，可使企业应用程序更接近数据源，例如 IoT 设备或本地边缘服务器。通过接近源头数据，可实现强大的业务优势，包括加快洞察过程、缩短响应时间、增强带宽可用性。
Reference
什么是物联网 (IoT)？ 物联网 (IoT) 是指由实体设备、车辆、电器和其他实体对象组成的网络，这些实体对象内嵌传感器、软件和网络连接，可以收集和共享数据。
Reference
什么是Kubernetes? Kubernetes 也称为 k8s 或 kube，是一个开源容器编排平台，用于调度和自动执行容器化应用程序的部署、管理和扩展。
Reference
什么是 Docker？ Docker 是创建和运行 Linux 容器的最流行工具。虽然数十年前人们就已经引入早期形式的容器（使用 FreeBSD Jails 和 AIX Workload Partitions 等技术），但在 2013 年，Docker 通过一种新的开发人员友好型和云友好型实现，将容器推向大众，从而实现了容器的民主化。
Docker 最初是一个开源项目，但今天，它也指 Docker Inc.，该公司生产 Docker（一个建立在开源项目基础上的商业容器工具包）并将这些改进回馈开源社区。
Docker 基于传统的 Linux 容器技术构建，但支持更精细的 Linux 内核进程虚拟化，并添加了一些功能，助力开发人员更轻松地构建、部署、管理和保护容器。
什么是容器? 容器是轻量级可执行应用程序组件，将源代码与在任何环境中运行代码所需的所有操作系统 (OS) 库和依赖关系相结合。
容器利用操作系统虚拟化形式，通过隔离进程并控制进程可以访问的 CPU、内存和磁盘量，实现多个应用程序共享单个操作系统实例。容器比虚拟机 (VM)更小、资源效率更高、更便携，已成为现代云原生应用程序事实上的计算单元。容器的资源效率也更高。它们允许您在更少的机器（虚拟服务器和物理服务器）上使用更少的操作系统实例运行更多的应用程序。
由于容器可以在随时随地一致地运行，因此它们对于支持混合多云环境的底层架构至关重要，混合多云环境是本地、私有云、公有云和来自多个云供应商的多个云服务的组合。
什么是人工智能 (AI)？ 人工智能 (AI) 是一种使计算机和机器能够模拟人类智能和解决问题能力的技术。
...</p></div><footer class=entry-footer><span title='2024-11-18 06:15:00 +0000 UTC'>November 18, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 什么是云算、超算、智算、通算" href=https://Pan-Binghong.github.io/daily-learning/knowledge/%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%91%E7%AE%97%E8%B6%85%E7%AE%97%E6%99%BA%E7%AE%97%E9%80%9A%E7%AE%97/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>LLM调优方法|巨™全</h2></header><div class=entry-content><p>💡 大语言模型调优方案, 涉及计算效能调优, 推理效果调优, 模型结构调优。
算效调优 硬件层面各个部件对大模型的优化策略
1. GPU加速 1.1 为什么GPU可以对大模型有加速效果? GPU的核心优势在于其并行处理能力，可以同时执行成千上万的计算任务。对于深度学习模型而言，这意味着可以并行处理大量的矩阵乘法和向量运算，这些是模型训练的核心。GPU的计算能力通常以TFLOPS（每秒万亿次浮点运算）来衡量。高TFLOPS值意味着GPU能够在较短的时间内完成更多的计算任务，从而加快模型的训练速度。
选择GPU而非CPU进行大模型训练的主要原因是因为GPU在并行处理能力、高吞吐量和针对机器学习任务的优化方面的优势。这使得GPU成为训练复杂和大规模机器学习模型的首选。
并行处理能力： 高吞吐量： 大规模计算： 优化的库和框架： 成本： 1.2 GPU里有什么,? Tensor Cores和CUDA Cores都是NVIDIA GPU架构中的关键组成部分，但它们的设计目标和服务的对象有所不同。下面详细介绍这两种核心的区别：
CUDA Cores CUDA Cores是NVIDIA GPU中的基础计算单元，类似于CPU中的核心，但专门为并行计算而优化。CUDA Cores能够执行各种类型的数学运算，包括整数运算、单精度浮点运算以及双精度浮点运算。CUDA Cores的数量决定了GPU的并行计算能力，更多的CUDA Cores意味着更强的并行处理能力。
CUDA Cores被设计为一种通用的计算资源，可以用于执行广泛的任务，从简单的图形渲染到复杂的科学计算，甚至是深度学习模型的训练。CUDA Cores支持通过CUDA编程接口直接访问，使得开发人员能够编写高效的并行计算代码。
Tensor Cores Tensor Cores是NVIDIA为加速深度学习任务而专门设计的一种新型计算单元。它们最早出现在2017年的Volta架构中，并随后在Turing、Ampere等架构中得到了发展和完善。Tensor Cores的主要特点是它们特别适合执行深度学习所需的矩阵运算，如矩阵乘法和累积运算。
Tensor Cores的一个重要特性是它们支持混合精度计算，即能够在FP16（半精度浮点数）和TF32（Tensor Float-32）之间进行切换，从而提供更高的计算效率和能效比。此外，Tensor Cores还能在每个时钟周期内执行多项操作，相比之下，传统的CUDA Cores在每个时钟周期只能执行单一操作。
CUDA Cores&amp;Tensor Cores区别 应用场景：CUDA Cores是通用的并行计算单元，可以处理各种计算任务；而Tensor Cores则专门针对深度学习中的矩阵运算进行了优化。 计算精度：CUDA Cores支持更广泛的精度计算，包括FP64、FP32和INT32等；Tensor Cores则专注于半精度浮点数（FP16）和混合精度计算（如TF32）。 性能：在处理深度学习相关的矩阵运算时，Tensor Cores相比CUDA Cores能够提供更高的性能和能效比。 CUDA Cores提供了广泛的计算灵活性，而Tensor Cores则是在特定任务上（如深度学习）实现了性能的飞跃。这两种核心的组合使得现代GPU既能满足传统计算需求，也能适应日益增长的人工智能计算需求。 1.3 主流GPU性能对比 1.4 训练/推理最佳配置 训练最优配置
推理最优配置
...</p></div><footer class=entry-footer><span title='2024-11-16 13:01:00 +0000 UTC'>November 16, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to LLM调优方法|巨™全" href=https://Pan-Binghong.github.io/daily-learning/knowledge/llm%E8%B0%83%E4%BC%98%E6%96%B9%E6%B3%95%E5%B7%A8%E5%85%A8/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>什么是RoCE、IB、RDMA</h2></header><div class=entry-content><p>💡 在分布式存储网络中，我们使用的协议有RoCE、Infiniband（IB）和TCP/IP。其中RoCE和IB属于RDMA(RemoteDirect Memory Access)技术，他和传统的TCP/IP有什么区别呢，接下来我们将做详细对比。
RoCE和IB，RDMA通述 什么是RoCE RoCE (译为”基于融合以太网的RDMA”, 英文全称: RDMA over Converged Ethernet)是一个网络协议,允许在一个以太网网络上使用远程直接内存访问（RDMA）。RoCE有RoCE v1和RoCE v2两个版本。RoCE v1是一个以太网链路层协议，因此允许同一个以太网广播域中的任意两台主机间进行通信。RoCE v2是一个网络层协议，因而RoCE v2数据包可以被路由。虽然RoCE协议受益于融合以太网网络的特征，但该协议也可用于传统或非融合的以太网网络。 什么是IB InfiniBand (直译为“无限带宽”技术，缩写为IB) 是一个用于高性能计算的计算机网络通信标准，它具有极高的吞吐量和极低的延迟，用于计算机与计算机之间的数据互连。InfiniBand也用作服务器与存储系统之间的直接或交换互连，以及存储系统之间的互连。 什么是RDMA RDMA (译为”远程直接内存访问”, 英文全称：remote direct memory access)是一种绕过远程主机操作系统内核访问其内存中数据的技术。由于不经过操作系统，不仅节省了大量CPU资源，同样也提高了系统吞吐量、降低了系统的网络通信延迟，尤其适合在大规模并行计算机集群中有广泛应用。 拓展
RoCE优缺点及关键技术 使用RoCE的优势 成本效益： 兼容性和灵活性： 易于管理： RoCE的缺点 性能： 可靠性： RoCE对比IB总结 IB和RoCE的区别为链路层一个为IB协议，一个为Ethernet协议，其中Ethernet协议更具有普适性，且大部分场景RoCE时延更低、带宽更高。 RoCE的关键技术 由于RDMA要求承载网络无丢包，否则效率就会急剧下降，所以RoCE技术如果选用以太网进行承载，就需要通过PFC，ECN以及DCQCN等技术对传统以太网络改造，打造无损以太网络，以确保零丢包。 PFC: ECN： RoCE应用趋势 当比较RoCE与其他类似的策略时，例如iWARP（Internet Wide Area RDMA Protocol）和传统的InfiniBand网络，我们可以看到一些显著的区别。 iWARP是一种通过TCP/IP协议栈实现RDMA的技术。虽然它可以在标准的三层网络中运行，但它的实现通常比RoCE复杂，并且可能需要更多的CPU资源来处理额外的软件堆栈。此外，iWARP在网络性能方面可能不如RoCE，尤其是在低延迟和高带宽的应用场景中。 InfiniBand是一种专为高性能计算设计的网络技术，它提供了极低的延迟和非常高的带宽。尽管InfiniBand在性能上优于RoCE，但它通常也更昂贵，并且需要专用的硬件。相比之下，RoCE可以在现有的以太网基础设施上运行，降低了部署成本。 随着RoCEv2的成熟和普及，它已成为数据中心网络中的一个主要趋势。越来越多的企业开始采用RoCEv2来支持高性能计算、机器学习和大规模存储集群等应用。RoCEv2的优势在于它能够在标准以太网上实现低延迟和高带宽的RDMA通信，同时保持较低的成本。 未来，随着对数据密集型应用需求的增长，RoCEv2将继续在其核心市场中发挥重要作用。随着技术的进步和新的应用场景的出现，RoCEv2可能会进一步优化以支持更广泛的用例，包括边缘计算和物联网（IoT）领域中的实时数据处理。 RoCEv2凭借其在性能和成本之间的平衡，正在成为数据中心网络架构中的关键技术之一，而RoCEv1则由于其局限性而在实际应用中逐渐被淘汰。随着网络技术和市场需求的不断发展，RoCEv2有望在未来的数据中心和高性能计算环境中扮演更加重要的角色。</p></div><footer class=entry-footer><span title='2024-11-16 12:19:00 +0000 UTC'>November 16, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 什么是RoCE、IB、RDMA" href=https://Pan-Binghong.github.io/daily-learning/knowledge/%E4%BB%80%E4%B9%88%E6%98%AFroceibrdma/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://Pan-Binghong.github.io/daily-learning/tags/knowledge/>«&nbsp;Prev&nbsp;</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://Pan-Binghong.github.io/daily-learning/>我的博客</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>
<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Knowledges | 我的博客</title><meta name=keywords content><meta name=description content="Knowledges - 我的博客"><meta name=author content="Pan Binghong"><link rel=canonical href=https://Pan-Binghong.github.io/knowledge/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://Pan-Binghong.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://Pan-Binghong.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://Pan-Binghong.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://Pan-Binghong.github.io/apple-touch-icon.png><link rel=mask-icon href=https://Pan-Binghong.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://Pan-Binghong.github.io/knowledge/index.xml title=rss><link rel=alternate hreflang=en href=https://Pan-Binghong.github.io/knowledge/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://Pan-Binghong.github.io/knowledge/"><meta property="og:site_name" content="我的博客"><meta property="og:title" content="Knowledges"><meta property="og:description" content="个人学习笔记博客"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Knowledges"><meta name=twitter:description content="个人学习笔记博客"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Knowledges","item":"https://Pan-Binghong.github.io/knowledge/"}]}</script></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://Pan-Binghong.github.io/ accesskey=h title="我的博客 (Alt + H)">我的博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://Pan-Binghong.github.io/ title=首页><span>首页</span></a></li><li><a href=https://Pan-Binghong.github.io/ai/ title=AI><span>AI</span></a></li><li><a href=https://Pan-Binghong.github.io/knowledge/ title=知识库><span class=active>知识库</span></a></li><li><a href=https://Pan-Binghong.github.io/backend/ title=后端><span>后端</span></a></li><li><a href=https://Pan-Binghong.github.io/devops/ title=DevOps><span>DevOps</span></a></li><li><a href=https://Pan-Binghong.github.io/other/ title=其他><span>其他</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Knowledges</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>大模型分布式训练_数据并行</h2></header><div class=entry-content><p>💡 记录并学习大模型分布式训练的方法以及原理等。
数据并行概述 数据并行是最简单的并行训练方法。在数据并行训练过程中，数据集被分割为n个部分，每个部分分配到一个GPU上。相当于按照:批次维度对训练进行并行化。同时每个GPU都将持有一个完整的模型副本，并在分配后的数据上进行训练。
数据并行（PyTorch DP） 缺点:
单进程多线程带来的问题：DataParallel使用单进程多线程进行实现的，方便了信息的交换，但受困于 GIL，会带来性能开销，速度很慢。而且，只能在单台服务器（单机多卡）上使用（不支持分布式）。同时，不能使用 Apex 进行混合精度训练。 效率问题，主卡性能和通信开销容易成为瓶颈，GPU 利用率通常很低：数据集需要先拷贝到主进程，然后再分片（split）到每个设备上；权重参数只在主卡（GPU0）上更新，需要每次迭代前向所有设备做一次同步；每次迭代的网络输出需要聚集到主卡（GPU0）上。因此，通信很快成为一个瓶颈。除此之外，这将导致主卡和其他卡之间，GPU利用率严重不均衡（比如：主卡使用了10G显存，而其他卡只使用了2G显存，batch size稍微设置大一点主卡的显存就OOM了）。 不支持模型并行，由于其本身的局限性，没办法与模型并行组合使用。 分布式数据并行 （PyTorch DDP） 计算过程:
首先将 rank=0 进程中的模型参数广播到进程组中的其他进程； 然后，每个 DDP 进程都会创建一个 local Reducer 来负责梯度同步。 在训练过程中，每个进程从磁盘加载 batch 数据，并将它们传递到其 GPU。每个 GPU 都有自己的前向过程，完成前向传播后，梯度在各个 GPUs 间进行 All-Reduce，每个 GPU 都收到其他 GPU 的梯度，从而可以独自进行反向传播和参数更新。 同时，每一层的梯度不依赖于前一层，所以梯度的 All-Reduce 和后向过程同时计算，以进一步缓解网络瓶颈。 在后向过程的最后，每个节点都得到了平均梯度，这样各个 GPU 中的模型参数保持同步 。 典型的数据并行实现方法:Pytorch DP/DDP 关键代码 单机数据并行的Pytorch代码实现 多机 DP和DDP的区别 DP是单进程多线程，只实用于单机。DDP是多进程实现，每个GPU表示一个进程，并且每个进程都是独立的Python解释器，DDP避免了GIL带来的性能开销。 更新参数方式 DDP支持模型并行，DP不支持。 补充ZeRO、FSDP 模型的训练运行占用的内存包含：模型权重，梯度值，激活值，数据(输入批次)和优化器状态。由于DDP在每个GPU上都copy了一份模型，因此DDP只能适用于能单卡放下模型时起到作用。以下是优化策略:
DeepSpeed(ZeRO) 激活检查点 全分片数据并行 Reference</p></div><footer class=entry-footer><span title='2024-12-30 07:01:00 +0000 UTC'>December 30, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 大模型分布式训练_数据并行" href=https://Pan-Binghong.github.io/knowledge/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83_%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Paper</h2></header><div class=entry-content><p>LLMs高效推理：综述
https://arxiv.org/abs/2404.14294
大型语言模型指令微调：综述
https://arxiv.org/pdf/2308.10792</p></div><footer class=entry-footer><span title='2024-12-04 01:05:00 +0000 UTC'>December 4, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to Paper" href=https://Pan-Binghong.github.io/knowledge/paper/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>什么是BM25检索算法</h2></header><div class=entry-content><p>💡 RAG中关于检索(Retriever)算法，BM25(Best Matching 25)详细了解一下。
它是一种经典的信息检索算法，是基于Okapi TF-IDF算法的改进版本，旨在解决Okapi TF-IDF算法的一些不足之处。其被广泛应用于信息检索领域的排名函数，用于估计文档D与用户查询Q之间的相关性。它是一种基于概率检索框架的改进，特别是在处理长文档和短查询时表现出色。BM25的核心思想是基于词频(TF)和逆文档频率(IDF)来,同时还引入了文档的长度信息来计算文档D和查询Q之间的相关性。目前被广泛运用的搜索引擎ES就内置了BM25算法进行全文检索。
Python代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 import math import jieba from collections import Counter class BM25: def __init__(self, k1=1.5, b=0.75): self.k1 = k1 # 词频饱和参数 self.b = b # 文档长度归一化参数 self.corpus = [] self.doc_lengths = [] self.avgdl = 0 self.doc_freqs = {} self.idf = {} self.doc_len = 0 def fit(self, corpus): """训练BM25模型""" self.corpus = [] # 对每个文档进行分词 for document in corpus: words = list(jieba.cut(document)) self.corpus.append(words) self.doc_lengths.append(len(words)) self.doc_len = len(self.corpus) self.avgdl = sum(self.doc_lengths) / self.doc_len # 计算词频和逆文档频率 for document in self.corpus: frequencies = Counter(document) for word, freq in frequencies.items(): if word not in self.doc_freqs: self.doc_freqs[word] = 0 self.doc_freqs[word] += 1 # 计算IDF值 for word, freq in self.doc_freqs.items(): self.idf[word] = math.log(1 + (self.doc_len - freq + 0.5)/(freq + 0.5)) def get_scores(self, query): """计算查询与所有文档的BM25得分""" query_words = list(jieba.cut(query)) scores = [0] * self.doc_len for word in query_words: if word not in self.doc_freqs: continue for idx, doc in enumerate(self.corpus): freq = Counter(doc)[word] numerator = self.idf[word] * freq * (self.k1 + 1) denominator = freq + self.k1 * (1 - self.b + self.b * self.doc_lengths[idx] / self.avgdl) scores[idx] += numerator / denominator return scores # 使用示例 if __name__ == "__main__": # 示例文档集合 documents = [ "我喜欢吃苹果和香蕉", "香蕉是一种水果", "苹果手机很受欢迎", "水果对健康有好处", "我最喜欢的水果是苹果" ] # 初始化BM25检索器 bm25 = BM25() # 训练模型 bm25.fit(documents) # 测试查询 query = "苹果水果" scores = bm25.get_scores(query) # 打印每个文档的得分 print("查询语句:", query) print("\n相关性得分:") for doc_id, score in enumerate(scores): print(f"文档 {doc_id + 1}: {documents[doc_id]}") print(f"BM25得分: {score:.4f}") 结果 References
...</p></div><footer class=entry-footer><span title='2024-12-02 10:52:00 +0000 UTC'>December 2, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 什么是BM25检索算法" href=https://Pan-Binghong.github.io/knowledge/%E4%BB%80%E4%B9%88%E6%98%AFbm25%E6%A3%80%E7%B4%A2%E7%AE%97%E6%B3%95/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>论文精度_HyDE</h2></header><div class=entry-content><p>💡 这里写创建该文章前的背景，心路历程。
记得常用分割线
https://python.langchain.com.cn/docs/templates/hyde
https://arxiv.org/pdf/2212.10496
引用链接用以下格式，比较好看~
Reference</p></div><footer class=entry-footer><span title='2024-11-28 07:59:00 +0000 UTC'>November 28, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 论文精度_HyDE" href=https://Pan-Binghong.github.io/knowledge/%E8%AE%BA%E6%96%87%E7%B2%BE%E5%BA%A6_hyde/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>论文精度_Query2doc</h2></header><div class=entry-content><p>💡 目前主流的检索方法有两种，稀疏检索和向量检索。这篇主要引出了一种新的查询方法，用于改进稀疏和向量检索。具体方法为：
Reference</p></div><footer class=entry-footer><span title='2024-11-28 07:58:00 +0000 UTC'>November 28, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 论文精度_Query2doc" href=https://Pan-Binghong.github.io/knowledge/%E8%AE%BA%E6%96%87%E7%B2%BE%E5%BA%A6_query2doc/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>论文精读_寻找RAG最优策略</h2></header><div class=entry-content><p>💡 这篇真的全是干货…论文的实验部分，我就不写了。看看就行。
相关工作|查询检索层面 确保大型语言模型（LLMs）如ChatGPT和LLaMA生成的回应准确性至关重要。然而，简单地增加模型大小并不能从根本上解决“幻觉”问题，这在知识密集型任务和专业领域尤为明显。检索增强生成（RAG）通过从外部知识库检索相关文档，为LLMs提供准确、实时、领域特定的上下文，以解决这些挑战。先前的工作通过查询和检索转换优化了RAG流程，提高了检索器的性能，并对检索器和生成器进行了微调。这些优化改善了输入查询、检索机制与生成过程之间的互动，确保了回应的准确性和相关性。
RAG工作流 在本节中，我们将详细介绍RAG工作流程的各个组件。针对每个模块，我们回顾常用的方法，并为我们的最终流程选择了默认和备选方法。
查询分类 并非所有的查询都需要通过检索增强，因为大型语言模型（LLMs）本身就具备一定的处理能力。尽管检索增强生成（RAG）可以提高信息的准确性并减少虚构内容，但频繁的检索可能会增加响应时间。因此，我们首先通过对查询进行分类来确定是否需要检索。需要检索的查询会经过RAG模块处理；其他则直接由LLMs处理。通常，在需要超出模型参数范围的知识时推荐使用检索。然而，检索的必要性根据任务的不同而有所变化。例如，一个训练至2023年的LLM可以处理“Sora是由OpenAI开发的”这一翻译请求而无需检索。相反，对于同一主题的介绍请求则需要检索来提供相关信息。
因此，我们建议按类型对任务进行分类，以确定查询是否需要检索。对于完全基于用户提供信息的任务，我们标记为“充分”，不需要检索；否则，我们标记为“不足”，可能需要检索。我们训练了一个分类器来自动化这一决策过程。
Chunking 将文档分块成更小的段落对于提高检索的准确性和避免在大型语言模型（LLMs）中出现长度问题至关重要。这个过程可以在不同的粒度级别上应用，比如令牌（token）、句子和语义级别。
令牌级别的分块很直接，但可能会分割句子，影响检索质量。 语义级别的分块利用大型语言模型来确定分割点，能保持上下文不变，但是耗时。 句子级别的分块在保留文本语义的同时，平衡了简单性和效率。 在这项研究中，我们使用句子级别的分块，平衡了简单性和语义保留。我们从四个维度考察了分块方法。 向量数据库存储着带有元数据的嵌入向量，通过各种索引和近似最近邻（ANN）方法，能够高效地检索与查询相关的文档。为了为我们的研究选择一个合适的向量数据库，我们基于四个关键标准对几个选项进行了评估：多种索引类型、支持十亿级别的向量、混合搜索以及云原生能力。这些标准因其对于灵活性、可扩展性以及在现代云基础设施中部署的便捷性的影响而被选中。多种索引类型提供了基于不同数据特性和用例优化搜索的灵活性。十亿级别的向量支持对于处理LLM应用中的大型数据集至关重要。混合搜索将向量搜索与传统关键词搜索结合起来，提高了检索准确性。最后，云原生能力确保了在云环境中的无缝集成、可扩展性和管理。
Retrieval方式 针对用户查询，检索模块从预建的语料库中选择与查询和文档的相似度最高的前k个相关文档。然后，生成模型使用这些文档来制定针对查询的适当响应。然而，原始查询由于表达不佳和缺乏语义信息，通常会表现不佳，这对检索过程产生了负面影响。为了解决这些问题，我们评估了三种查询转换方法，使用推荐的LLM-Embedder作为查询和文档编码器：
查询改写：查询改写通过改进查询来更好地匹配相关文档。受到Rewrite-Retrieve-Read框架的启发，我们促使一个LLM重写查询以提升性能。 查询分解：这种方法涉及到基于从原始查询中派生的子问题来检索文档，这比理解和处理更复杂的查询要困难。 伪文档生成：这种方法基于用户查询生成一个假想的文档，并使用假想答案的嵌入来检索相似文档。一个值得注意的实现是HyDE。 最近的研究表明结合基于词汇的搜索与向量搜索可以显著提高性能。在本研究中，我们使用BM25进行稀疏检索和Contriever，一个无监督对比编码器，进行密集检索。 Reranking 在最初的检索之后，将采用重排序阶段来提高检索到的文档的相关性，确保最相关的信息出现在列表的顶部。这一阶段采用更精确、耗时更长的方法有效地重新排序文档，增加查询与排名最高的文档之间的相似度。
在我们的重排序模块中，我们考虑了两种方法：DLM重排序和TILDE重排序。DLM重排序采用分类方法，而TILDE重排序则侧重于查询可能性。这些方法分别优先考虑性能和效率。
DLM重排方法：这种方法利用深度语言模型（DLMs）进行重排。这些模型被微调用以将文档与查询的相关性分类为“真”或“假”。在微调过程中，模型通过将查询和文档输入连接起来，并根据相关性进行标记来进行训练。在推理时，文档根据“真”标记的概率进行排名。 TILDE重排：TILDE通过预测模型词汇表中的各个词项的概率来独立计算每个查询词项的可能性。通过对查询词项的预计算对数概率求和，为文档打分，从而在推理时快速重排。TILDEv2通过仅索引文档中存在的词项，使用NCE损失，并扩展文档，从而提高效率并减小索引大小。 我们的实验是在MS MARCO Passage排名数据集上进行的，这是一个大规模的机器阅读理解数据集。我们遵循并对PyGaggle和TILDE提供的实现进行了修改，使用了模型monoT5、monoBERT、RankLLaMA和TILDEv2。重排结果显示在表中。我们推荐monoT5作为一种综合性的方法，平衡了性能和效率。RankLLaMA适合于实现最佳性能，而TILDEv2是在固定集合上获得最快体验的理想选择。实验设置和结果的详细信息在附录中呈现。 文档重组 文档重组后续过程的表现，比如LLM响应生成，可能会受到提供文档的顺序影响。为了解决这个问题，在重新排名之后的工作流程中，我们加入了一个紧凑的重组模块，包含三种重组方法：“前向”、“反向”和“两侧”。“前向”方法通过降序重新排名阶段的相关性得分来重组文档，而“反向”则按升序排列它们。对于LLM，当相关信息放在输入的头部或尾部时，可以达到最佳性能，我们也加入了“两侧”选项。
Reference</p></div><footer class=entry-footer><span title='2024-11-28 07:08:00 +0000 UTC'>November 28, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 论文精读_寻找RAG最优策略" href=https://Pan-Binghong.github.io/knowledge/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB_%E5%AF%BB%E6%89%BErag%E6%9C%80%E4%BC%98%E7%AD%96%E7%95%A5/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>什么是Unicode字符集以及UTF8编码</h2></header><div class=entry-content><p>两者的关系 Unicode 是字符集的规范，它定义了字符与码点的对应关系，但并不涉及具体的编码实现。 UTF-8 是一种编码方案，将 Unicode 码点转换为适合计算机存储和传输的字节序列。 类比： Unicode 是一本“词典”，记录了每个字符的编号。 UTF-8 是“包装方式”，将这些编号转换为计算机能处理的格式。 拓展 Python代码帮助理解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # Unicode字符集示例 # 1. 基本的Unicode字符串 simple_string = "你好，世界！" print("1. 基本Unicode字符串:", simple_string) # 2. Unicode编码和解码 # 使用encode()将字符串编码为bytes encoded_string = simple_string.encode('utf-8') print("2. UTF-8编码后:", encoded_string) # 使用decode()将bytes解码回字符串 decoded_string = encoded_string.decode('utf-8') print("2. 解码回字符串:", decoded_string) # 3. Unicode转义序列 unicode_escape = "\u4F60\u597D" # "你好"的Unicode编码 print("3. Unicode转义序列:", unicode_escape) # 4. 处理不同的Unicode字符 special_chars = "🌟✨🎈🎉" # emoji表情 print("4. 特殊Unicode字符(emoji):", special_chars) # 5. 获取字符的Unicode编码点 char = "中" unicode_point = ord(char) print(f"5. '中'的Unicode码点: {unicode_point} (十进制)") print(f"5. '中'的Unicode码点: {hex(unicode_point)} (十六进制)") # 6. 从编码点创建字符 code_point = 0x4E2D # "中"的Unicode编码点 character = chr(code_point) print(f"6. 从编码点创建字符: {character}") 结果展示 References
...</p></div><footer class=entry-footer><span title='2024-11-25 01:30:00 +0000 UTC'>November 25, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 什么是Unicode字符集以及UTF8编码" href=https://Pan-Binghong.github.io/knowledge/%E4%BB%80%E4%B9%88%E6%98%AFunicode%E5%AD%97%E7%AC%A6%E9%9B%86%E4%BB%A5%E5%8F%8Autf8%E7%BC%96%E7%A0%81/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>什么是ASCII字符集</h2></header><div class=entry-content><p>💡 （American Standard Code for Information Interchange，美国信息交换标准代码）是计算机科学中的一种字符编码标准，用于表示文本数据。它为每个字符分配了一个唯一的数字编码，主要用于通信设备、计算机和其他电子设备之间的数据交换。
特点 范围： ASCII码使用7位二进制数（0到127）来表示字符，共定义了128个字符。00000001
数字：0-9 （ASCII值为48到57） 大写字母：A-Z （ASCII值为65到90） 小写字母：a-z （ASCII值为97到122） 特殊符号：如空格（32）、换行（10）、感叹号（33）、@（64）等。 控制字符：如回车（13）、换页（12）、删除（127）等。 详细一览 为什么只使用7位？ 早期计算机内存和存储资源有限，使用7位编码能够节省空间，同时满足当时的英文字符需求（128个字符足够表示所有常用符号和字母）。后来为了支持更多语言和符号，扩展了8位（256个字符）的编码，称为扩展ASCII。
Python实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def show_ascii_info(char): """ 显示字符对应的ASCII码信息 参数: char - 要查看的字符 返回: 包含ASCII信息的字符串 """ ascii_value = ord(char) binary_value = bin(ascii_value)[2:].zfill(8) # 转换为8位二进制 hex_value = hex(ascii_value)[2:].upper() # 转换为16进制 return f""" 字符 '{char}' 的ASCII信息: - ASCII码值: {ascii_value} - 二进制: {binary_value} - 十六进制: {hex_value} """ def show_common_ascii(): """显示一些常见的ASCII码范围""" print("\n常见ASCII码范围:") print("1. 数字 (48-57):") for i in range(48, 58): print(f"{chr(i)} = {i}") print("\n2. 大写字母 (65-90):") for i in range(65, 91): print(f"{chr(i)} = {i}") print("\n3. 小写字母 (97-122):") for i in range(97, 123): print(f"{chr(i)} = {i}") def main(): print("ASCII码学习程序") print("-" * 30) # 测试一些字符 test_chars = ['A', '1', 'z', '@', '中'] # 注意：'中'是Unicode字符 for char in test_chars: try: print(show_ascii_info(char)) except ValueError: print(f"注意: '{char}' 不是ASCII字符") # 显示常见ASCII码范围 show_common_ascii() # 交互式测试 while True: user_input = input("\n请输入一个字符(按回车退出): ") if not user_input: break try: print(show_ascii_info(user_input[0])) except ValueError: print(f"注意: '{user_input[0]}' 不是ASCII字符") if __name__ == "__main__": main() Reference
...</p></div><footer class=entry-footer><span title='2024-11-24 14:36:00 +0000 UTC'>November 24, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 什么是ASCII字符集" href=https://Pan-Binghong.github.io/knowledge/%E4%BB%80%E4%B9%88%E6%98%AFascii%E5%AD%97%E7%AC%A6%E9%9B%86/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>什么是Base64</h2></header><div class=entry-content><p>💡 记录一下Base64原理，优点之类的。
概念解释 Base64是一种基于64个可打印字符来表示二进制数据的表示方法。
常用于在不支持二进制数据的场合（如电子邮件、URL等）传输二进制数据。
应用场景 电子邮件中嵌入图片或者其他二进制文件。 Web开发内，将小图片编码为Base64字符串，减少HTTP请求次数。 在编程语言内，用于对字符串进行编码和解码。 关于Base64编码格式的经典问题 Base64编码优缺点 Base64编码后的字符串为什么会变长？ Base64编码后的字符串末尾为什么会出现“=”号？ Base64 Alphabet Python代码实现Base64编码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def base(string:str)->str: oldstr = '' newstr = [] base = '' base64_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P','Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v','w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '/'] #把原始字符串转换为二进制，用bin转换后是0b开头的，所以把b替换了，首位补0补齐8位 for i in string: oldstr += '{:08}'.format(int(str(bin(ord(i))).replace('0b', ''))) #把转换好的二进制按照6位一组分好，最后一组不足6位的后面补0 for j in range(0, len(oldstr), 6): newstr.append('{:&lt;06}'.format(oldstr[j:j + 6])) #在base_list中找到对应的字符，拼接 for l in range(len(newstr)): base += base64_list[int(newstr[l], 2)] #判断base字符结尾补几个‘=’ if len(string) % 3 == 1: base += '==' elif len(string) % 3 == 2: base += '=' return base Base64包实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 import base64 from pathlib import Path def base64_converter(text, mode='encode', output_path=None): """ 处理base64编解码的函数 参数: text (str/Path/bytes): 要处理的文本、图片文件路径或base64编码的bytes mode (str): 'encode' 用于编码，'decode' 用于解码 output_path (str/Path): 解码图片时的保存路径，默认为None """ # 处理文本字符串 if isinstance(text, str) and not Path(text).is_file(): if mode == 'encode': text_bytes = text.encode('utf-8') encoded = base64.b64encode(text_bytes) return encoded.decode('utf-8') else: decoded = base64.b64decode(text) return decoded.decode('utf-8') # 处理图片文件或bytes数据 if mode == 'encode': if isinstance(text, bytes): return base64.b64encode(text) with open(text, 'rb') as image_file: return base64.b64encode(image_file.read()) else: # 使用指定的输出路径或当前目录 save_path = Path(output_path) if output_path else Path.cwd() / "decoded_image.png" save_path.parent.mkdir(parents=True, exist_ok=True) # 解码并保存图片 if isinstance(text, bytes): image_data = base64.b64decode(text) else: image_data = base64.b64decode(text.encode('ascii') if isinstance(text, str) else text) with open(save_path, 'wb') as image_file: image_file.write(image_data) return f"图片已保存到: {save_path.absolute()}" if __name__ == "__main__": # 文本编解码测试 result = base64_converter("Hello, World!", mode='encode') print("编码结果:", result) decoded = base64_converter(result, mode='decode') print("解码结果:", decoded) # 图片编解码测试 test_image_path = "test.png" if Path(test_image_path).exists(): # 编码图片 image_base64 = base64_converter(test_image_path, mode='encode') # 解码到输出文件 result = base64_converter(image_base64, mode='decode', output_path="decoded_test.png") print(result) ...</p></div><footer class=entry-footer><span title='2024-11-24 02:53:00 +0000 UTC'>November 24, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 什么是Base64" href=https://Pan-Binghong.github.io/knowledge/%E4%BB%80%E4%B9%88%E6%98%AFbase64/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>国内外算力卡调研</h2></header><div class=entry-content><p>💡 emmm…涉及敏感信息。。。这篇就不发布出来了。有需要可以单独联系我。</p></div><footer class=entry-footer><span title='2024-11-18 07:21:00 +0000 UTC'>November 18, 2024</span>&nbsp;·&nbsp;<span>Pan Binghong</span></footer><a class=entry-link aria-label="post link to 国内外算力卡调研" href=https://Pan-Binghong.github.io/knowledge/%E5%9B%BD%E5%86%85%E5%A4%96%E7%AE%97%E5%8A%9B%E5%8D%A1%E8%B0%83%E7%A0%94/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://Pan-Binghong.github.io/knowledge/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://Pan-Binghong.github.io/knowledge/page/3/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://Pan-Binghong.github.io/>我的博客</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>
<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Learning vLL (0.7.2) with Cursor | æˆ‘çš„åšå®¢</title><meta name=keywords content="VLLM"><meta name=description content='
ğŸ’¡ ä¹‹å‰ä¸€ç›´ç”¨cursorè¾…åŠ©å†™ä»£ç ï¼Œçªç„¶è¯•äº†ä¸€ä¸‹å»åˆ©ç”¨cursoræ¥å­¦ä»£ç ï¼Œå‘ç°æ•ˆæœå˜å˜å¥½ã€‚è¿™é‡Œè®°å½•ä¸€ä¸‹æ¯”è¾ƒç«çš„vllmä¸­æå‡æ¨ç†é€Ÿåº¦çš„ä¸€äº›å…³é”®ä»£ç ã€‚

1. What is vLLMï¼Ÿ

vLLMæ˜¯å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿæ¡†æ¶ã€‚ä¸»è¦åœ¨KVcacheç®¡ç†ä¸­é‡‡ç”¨äº†PageAttentionæŠ€æœ¯ï¼Œæ”¯æŒå¸‚é¢ä¸Šä¸»æµçš„å¼€æºå¤§æ¨¡å‹ï¼Œæ”¯æŒé‡åŒ–ç±»å‹ä¸ºï¼šGPTQ,Â AWQ, INT4, INT8, and FP8

2. KVcacheç›¸å…³çš„è®¡ç®—ä»£ç 
ä½¿ç”¨claude-3.7-sonnet thinkingï¼Œå¯¹vllmæ•´ä¸ªé¡¹ç›®è¿›è¡Œæé—®ã€‚

ä¸ºäº†æ›´å¥½ä¸¾ä¾‹ï¼Œä¸‹è½½äº†deepseek-v3-0324ç‰ˆæœ¬çš„config.jsonï¼Œä»£å…¥é¡¹ç›®è¿›è¡Œæé—®ã€‚


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71


{
  "architectures": [
    "DeepseekV3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "auto_map": {
    "AutoConfig": "configuration_deepseek.DeepseekV3Config",
    "AutoModel": "modeling_deepseek.DeepseekV3Model",
    "AutoModelForCausalLM": "modeling_deepseek.DeepseekV3ForCausalLM"
  },
  "aux_loss_alpha": 0.001,
  "bos_token_id": 0,
  "eos_token_id": 1,
  "ep_size": 1,
  "first_k_dense_replace": 3,
  "hidden_act": "silu",
  "hidden_size": 7168,
  "initializer_range": 0.02,
  "intermediate_size": 18432,
  "kv_lora_rank": 512,
  "max_position_embeddings": 163840,
  "model_type": "deepseek_v3",
  "moe_intermediate_size": 2048,
  "moe_layer_freq": 1,
  "n_group": 8,
  "n_routed_experts": 256,
  "n_shared_experts": 1,
  "norm_topk_prob": true,
  "num_attention_heads": 128,
  "num_experts_per_tok": 8,
  "num_hidden_layers": 61,
  "num_key_value_heads": 128,
  "num_nextn_predict_layers": 1,
  "pretraining_tp": 1,æ¨¡å‹ä¸­Transformerå±‚çš„æ•°é‡ã€‚æ›´å¤šçš„å±‚æ•°ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ›´æ·±å±‚æ¬¡çš„ç‰¹å¾å’Œå…³ç³»ï¼Œä½†ä¹Ÿå¢åŠ äº†æ¨¡å‹çš„æ·±åº¦å’Œè®¡ç®—æˆæœ¬ã€‚

  "q_lora_rank": 1536,
  "qk_nope_head_dim": 128,
  "qk_rope_head_dim": 64,
  "quantization_config": {
    "activation_scheme": "dynamic",
    "fmt": "e4m3",
    "quant_method": "fp8",
    "weight_block_size": [
      128,
      128
    ]
  },
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "beta_fast": 32,
    "beta_slow": 1,
    "factor": 40,
    "mscale": 1.0,
    "mscale_all_dim": 1.0,
    "original_max_position_embeddings": 4096,
    "type": "yarn"
  },
  "rope_theta": 10000,
  "routed_scaling_factor": 2.5,
  "scoring_func": "sigmoid",
  "seq_aux": true,
  "tie_word_embeddings": false,
  "topk_group": 4,
  "topk_method": "noaux_tc",
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.3",
  "use_cache": true,
  "v_head_dim": 128,
  "vocab_size": 129280
}


è¯¥æ–‡ä»¶ä¸­çš„å…³é”®ä¿¡æ¯ä¸ºï¼š'><meta name=author content="Pan Binghong"><link rel=canonical href=https://Pan-Binghong.github.io/daily-learning/ai/learning-vll-0.7.2-with-cursor/><link crossorigin=anonymous href=/daily-learning/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://Pan-Binghong.github.io/daily-learning/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://Pan-Binghong.github.io/daily-learning/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://Pan-Binghong.github.io/daily-learning/favicon-32x32.png><link rel=apple-touch-icon href=https://Pan-Binghong.github.io/daily-learning/apple-touch-icon.png><link rel=mask-icon href=https://Pan-Binghong.github.io/daily-learning/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://Pan-Binghong.github.io/daily-learning/ai/learning-vll-0.7.2-with-cursor/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://Pan-Binghong.github.io/daily-learning/ai/learning-vll-0.7.2-with-cursor/"><meta property="og:site_name" content="æˆ‘çš„åšå®¢"><meta property="og:title" content="Learning vLL (0.7.2) with Cursor"><meta property="og:description" content=' ğŸ’¡ ä¹‹å‰ä¸€ç›´ç”¨cursorè¾…åŠ©å†™ä»£ç ï¼Œçªç„¶è¯•äº†ä¸€ä¸‹å»åˆ©ç”¨cursoræ¥å­¦ä»£ç ï¼Œå‘ç°æ•ˆæœå˜å˜å¥½ã€‚è¿™é‡Œè®°å½•ä¸€ä¸‹æ¯”è¾ƒç«çš„vllmä¸­æå‡æ¨ç†é€Ÿåº¦çš„ä¸€äº›å…³é”®ä»£ç ã€‚
1. What is vLLMï¼Ÿ vLLMæ˜¯å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿæ¡†æ¶ã€‚ä¸»è¦åœ¨KVcacheç®¡ç†ä¸­é‡‡ç”¨äº†PageAttentionæŠ€æœ¯ï¼Œæ”¯æŒå¸‚é¢ä¸Šä¸»æµçš„å¼€æºå¤§æ¨¡å‹ï¼Œæ”¯æŒé‡åŒ–ç±»å‹ä¸ºï¼šGPTQ,Â AWQ, INT4, INT8, and FP8
2. KVcacheç›¸å…³çš„è®¡ç®—ä»£ç  ä½¿ç”¨claude-3.7-sonnet thinkingï¼Œå¯¹vllmæ•´ä¸ªé¡¹ç›®è¿›è¡Œæé—®ã€‚
ä¸ºäº†æ›´å¥½ä¸¾ä¾‹ï¼Œä¸‹è½½äº†deepseek-v3-0324ç‰ˆæœ¬çš„config.jsonï¼Œä»£å…¥é¡¹ç›®è¿›è¡Œæé—®ã€‚
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 { "architectures": [ "DeepseekV3ForCausalLM" ], "attention_bias": false, "attention_dropout": 0.0, "auto_map": { "AutoConfig": "configuration_deepseek.DeepseekV3Config", "AutoModel": "modeling_deepseek.DeepseekV3Model", "AutoModelForCausalLM": "modeling_deepseek.DeepseekV3ForCausalLM" }, "aux_loss_alpha": 0.001, "bos_token_id": 0, "eos_token_id": 1, "ep_size": 1, "first_k_dense_replace": 3, "hidden_act": "silu", "hidden_size": 7168, "initializer_range": 0.02, "intermediate_size": 18432, "kv_lora_rank": 512, "max_position_embeddings": 163840, "model_type": "deepseek_v3", "moe_intermediate_size": 2048, "moe_layer_freq": 1, "n_group": 8, "n_routed_experts": 256, "n_shared_experts": 1, "norm_topk_prob": true, "num_attention_heads": 128, "num_experts_per_tok": 8, "num_hidden_layers": 61, "num_key_value_heads": 128, "num_nextn_predict_layers": 1, "pretraining_tp": 1,æ¨¡å‹ä¸­Transformerå±‚çš„æ•°é‡ã€‚æ›´å¤šçš„å±‚æ•°ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ›´æ·±å±‚æ¬¡çš„ç‰¹å¾å’Œå…³ç³»ï¼Œä½†ä¹Ÿå¢åŠ äº†æ¨¡å‹çš„æ·±åº¦å’Œè®¡ç®—æˆæœ¬ã€‚ "q_lora_rank": 1536, "qk_nope_head_dim": 128, "qk_rope_head_dim": 64, "quantization_config": { "activation_scheme": "dynamic", "fmt": "e4m3", "quant_method": "fp8", "weight_block_size": [ 128, 128 ] }, "rms_norm_eps": 1e-06, "rope_scaling": { "beta_fast": 32, "beta_slow": 1, "factor": 40, "mscale": 1.0, "mscale_all_dim": 1.0, "original_max_position_embeddings": 4096, "type": "yarn" }, "rope_theta": 10000, "routed_scaling_factor": 2.5, "scoring_func": "sigmoid", "seq_aux": true, "tie_word_embeddings": false, "topk_group": 4, "topk_method": "noaux_tc", "torch_dtype": "bfloat16", "transformers_version": "4.46.3", "use_cache": true, "v_head_dim": 128, "vocab_size": 129280 } è¯¥æ–‡ä»¶ä¸­çš„å…³é”®ä¿¡æ¯ä¸ºï¼š'><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="ai"><meta property="article:published_time" content="2025-04-14T00:38:00+00:00"><meta property="article:modified_time" content="2025-04-14T09:00:00+00:00"><meta property="article:tag" content="VLLM"><meta name=twitter:card content="summary"><meta name=twitter:title content="Learning vLL (0.7.2) with Cursor"><meta name=twitter:description content='
ğŸ’¡ ä¹‹å‰ä¸€ç›´ç”¨cursorè¾…åŠ©å†™ä»£ç ï¼Œçªç„¶è¯•äº†ä¸€ä¸‹å»åˆ©ç”¨cursoræ¥å­¦ä»£ç ï¼Œå‘ç°æ•ˆæœå˜å˜å¥½ã€‚è¿™é‡Œè®°å½•ä¸€ä¸‹æ¯”è¾ƒç«çš„vllmä¸­æå‡æ¨ç†é€Ÿåº¦çš„ä¸€äº›å…³é”®ä»£ç ã€‚

1. What is vLLMï¼Ÿ

vLLMæ˜¯å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿæ¡†æ¶ã€‚ä¸»è¦åœ¨KVcacheç®¡ç†ä¸­é‡‡ç”¨äº†PageAttentionæŠ€æœ¯ï¼Œæ”¯æŒå¸‚é¢ä¸Šä¸»æµçš„å¼€æºå¤§æ¨¡å‹ï¼Œæ”¯æŒé‡åŒ–ç±»å‹ä¸ºï¼šGPTQ,Â AWQ, INT4, INT8, and FP8

2. KVcacheç›¸å…³çš„è®¡ç®—ä»£ç 
ä½¿ç”¨claude-3.7-sonnet thinkingï¼Œå¯¹vllmæ•´ä¸ªé¡¹ç›®è¿›è¡Œæé—®ã€‚

ä¸ºäº†æ›´å¥½ä¸¾ä¾‹ï¼Œä¸‹è½½äº†deepseek-v3-0324ç‰ˆæœ¬çš„config.jsonï¼Œä»£å…¥é¡¹ç›®è¿›è¡Œæé—®ã€‚


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71


{
  "architectures": [
    "DeepseekV3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "auto_map": {
    "AutoConfig": "configuration_deepseek.DeepseekV3Config",
    "AutoModel": "modeling_deepseek.DeepseekV3Model",
    "AutoModelForCausalLM": "modeling_deepseek.DeepseekV3ForCausalLM"
  },
  "aux_loss_alpha": 0.001,
  "bos_token_id": 0,
  "eos_token_id": 1,
  "ep_size": 1,
  "first_k_dense_replace": 3,
  "hidden_act": "silu",
  "hidden_size": 7168,
  "initializer_range": 0.02,
  "intermediate_size": 18432,
  "kv_lora_rank": 512,
  "max_position_embeddings": 163840,
  "model_type": "deepseek_v3",
  "moe_intermediate_size": 2048,
  "moe_layer_freq": 1,
  "n_group": 8,
  "n_routed_experts": 256,
  "n_shared_experts": 1,
  "norm_topk_prob": true,
  "num_attention_heads": 128,
  "num_experts_per_tok": 8,
  "num_hidden_layers": 61,
  "num_key_value_heads": 128,
  "num_nextn_predict_layers": 1,
  "pretraining_tp": 1,æ¨¡å‹ä¸­Transformerå±‚çš„æ•°é‡ã€‚æ›´å¤šçš„å±‚æ•°ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ›´æ·±å±‚æ¬¡çš„ç‰¹å¾å’Œå…³ç³»ï¼Œä½†ä¹Ÿå¢åŠ äº†æ¨¡å‹çš„æ·±åº¦å’Œè®¡ç®—æˆæœ¬ã€‚

  "q_lora_rank": 1536,
  "qk_nope_head_dim": 128,
  "qk_rope_head_dim": 64,
  "quantization_config": {
    "activation_scheme": "dynamic",
    "fmt": "e4m3",
    "quant_method": "fp8",
    "weight_block_size": [
      128,
      128
    ]
  },
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "beta_fast": 32,
    "beta_slow": 1,
    "factor": 40,
    "mscale": 1.0,
    "mscale_all_dim": 1.0,
    "original_max_position_embeddings": 4096,
    "type": "yarn"
  },
  "rope_theta": 10000,
  "routed_scaling_factor": 2.5,
  "scoring_func": "sigmoid",
  "seq_aux": true,
  "tie_word_embeddings": false,
  "topk_group": 4,
  "topk_method": "noaux_tc",
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.3",
  "use_cache": true,
  "v_head_dim": 128,
  "vocab_size": 129280
}


è¯¥æ–‡ä»¶ä¸­çš„å…³é”®ä¿¡æ¯ä¸ºï¼š'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Ais","item":"https://Pan-Binghong.github.io/daily-learning/ai/"},{"@type":"ListItem","position":2,"name":"Learning vLL (0.7.2) with Cursor","item":"https://Pan-Binghong.github.io/daily-learning/ai/learning-vll-0.7.2-with-cursor/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Learning vLL (0.7.2) with Cursor","name":"Learning vLL (0.7.2) with Cursor","description":" ğŸ’¡ ä¹‹å‰ä¸€ç›´ç”¨cursorè¾…åŠ©å†™ä»£ç ï¼Œçªç„¶è¯•äº†ä¸€ä¸‹å»åˆ©ç”¨cursoræ¥å­¦ä»£ç ï¼Œå‘ç°æ•ˆæœå˜å˜å¥½ã€‚è¿™é‡Œè®°å½•ä¸€ä¸‹æ¯”è¾ƒç«çš„vllmä¸­æå‡æ¨ç†é€Ÿåº¦çš„ä¸€äº›å…³é”®ä»£ç ã€‚\n1. What is vLLMï¼Ÿ vLLMæ˜¯å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿæ¡†æ¶ã€‚ä¸»è¦åœ¨KVcacheç®¡ç†ä¸­é‡‡ç”¨äº†PageAttentionæŠ€æœ¯ï¼Œæ”¯æŒå¸‚é¢ä¸Šä¸»æµçš„å¼€æºå¤§æ¨¡å‹ï¼Œæ”¯æŒé‡åŒ–ç±»å‹ä¸ºï¼šGPTQ,Â AWQ, INT4, INT8, and FP8\n2. KVcacheç›¸å…³çš„è®¡ç®—ä»£ç  ä½¿ç”¨claude-3.7-sonnet thinkingï¼Œå¯¹vllmæ•´ä¸ªé¡¹ç›®è¿›è¡Œæé—®ã€‚\nä¸ºäº†æ›´å¥½ä¸¾ä¾‹ï¼Œä¸‹è½½äº†deepseek-v3-0324ç‰ˆæœ¬çš„config.jsonï¼Œä»£å…¥é¡¹ç›®è¿›è¡Œæé—®ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 { \u0026#34;architectures\u0026#34;: [ \u0026#34;DeepseekV3ForCausalLM\u0026#34; ], \u0026#34;attention_bias\u0026#34;: false, \u0026#34;attention_dropout\u0026#34;: 0.0, \u0026#34;auto_map\u0026#34;: { \u0026#34;AutoConfig\u0026#34;: \u0026#34;configuration_deepseek.DeepseekV3Config\u0026#34;, \u0026#34;AutoModel\u0026#34;: \u0026#34;modeling_deepseek.DeepseekV3Model\u0026#34;, \u0026#34;AutoModelForCausalLM\u0026#34;: \u0026#34;modeling_deepseek.DeepseekV3ForCausalLM\u0026#34; }, \u0026#34;aux_loss_alpha\u0026#34;: 0.001, \u0026#34;bos_token_id\u0026#34;: 0, \u0026#34;eos_token_id\u0026#34;: 1, \u0026#34;ep_size\u0026#34;: 1, \u0026#34;first_k_dense_replace\u0026#34;: 3, \u0026#34;hidden_act\u0026#34;: \u0026#34;silu\u0026#34;, \u0026#34;hidden_size\u0026#34;: 7168, \u0026#34;initializer_range\u0026#34;: 0.02, \u0026#34;intermediate_size\u0026#34;: 18432, \u0026#34;kv_lora_rank\u0026#34;: 512, \u0026#34;max_position_embeddings\u0026#34;: 163840, \u0026#34;model_type\u0026#34;: \u0026#34;deepseek_v3\u0026#34;, \u0026#34;moe_intermediate_size\u0026#34;: 2048, \u0026#34;moe_layer_freq\u0026#34;: 1, \u0026#34;n_group\u0026#34;: 8, \u0026#34;n_routed_experts\u0026#34;: 256, \u0026#34;n_shared_experts\u0026#34;: 1, \u0026#34;norm_topk_prob\u0026#34;: true, \u0026#34;num_attention_heads\u0026#34;: 128, \u0026#34;num_experts_per_tok\u0026#34;: 8, \u0026#34;num_hidden_layers\u0026#34;: 61, \u0026#34;num_key_value_heads\u0026#34;: 128, \u0026#34;num_nextn_predict_layers\u0026#34;: 1, \u0026#34;pretraining_tp\u0026#34;: 1,æ¨¡å‹ä¸­Transformerå±‚çš„æ•°é‡ã€‚æ›´å¤šçš„å±‚æ•°ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ›´æ·±å±‚æ¬¡çš„ç‰¹å¾å’Œå…³ç³»ï¼Œä½†ä¹Ÿå¢åŠ äº†æ¨¡å‹çš„æ·±åº¦å’Œè®¡ç®—æˆæœ¬ã€‚ \u0026#34;q_lora_rank\u0026#34;: 1536, \u0026#34;qk_nope_head_dim\u0026#34;: 128, \u0026#34;qk_rope_head_dim\u0026#34;: 64, \u0026#34;quantization_config\u0026#34;: { \u0026#34;activation_scheme\u0026#34;: \u0026#34;dynamic\u0026#34;, \u0026#34;fmt\u0026#34;: \u0026#34;e4m3\u0026#34;, \u0026#34;quant_method\u0026#34;: \u0026#34;fp8\u0026#34;, \u0026#34;weight_block_size\u0026#34;: [ 128, 128 ] }, \u0026#34;rms_norm_eps\u0026#34;: 1e-06, \u0026#34;rope_scaling\u0026#34;: { \u0026#34;beta_fast\u0026#34;: 32, \u0026#34;beta_slow\u0026#34;: 1, \u0026#34;factor\u0026#34;: 40, \u0026#34;mscale\u0026#34;: 1.0, \u0026#34;mscale_all_dim\u0026#34;: 1.0, \u0026#34;original_max_position_embeddings\u0026#34;: 4096, \u0026#34;type\u0026#34;: \u0026#34;yarn\u0026#34; }, \u0026#34;rope_theta\u0026#34;: 10000, \u0026#34;routed_scaling_factor\u0026#34;: 2.5, \u0026#34;scoring_func\u0026#34;: \u0026#34;sigmoid\u0026#34;, \u0026#34;seq_aux\u0026#34;: true, \u0026#34;tie_word_embeddings\u0026#34;: false, \u0026#34;topk_group\u0026#34;: 4, \u0026#34;topk_method\u0026#34;: \u0026#34;noaux_tc\u0026#34;, \u0026#34;torch_dtype\u0026#34;: \u0026#34;bfloat16\u0026#34;, \u0026#34;transformers_version\u0026#34;: \u0026#34;4.46.3\u0026#34;, \u0026#34;use_cache\u0026#34;: true, \u0026#34;v_head_dim\u0026#34;: 128, \u0026#34;vocab_size\u0026#34;: 129280 } è¯¥æ–‡ä»¶ä¸­çš„å…³é”®ä¿¡æ¯ä¸ºï¼š\n","keywords":["VLLM"],"articleBody":" ğŸ’¡ ä¹‹å‰ä¸€ç›´ç”¨cursorè¾…åŠ©å†™ä»£ç ï¼Œçªç„¶è¯•äº†ä¸€ä¸‹å»åˆ©ç”¨cursoræ¥å­¦ä»£ç ï¼Œå‘ç°æ•ˆæœå˜å˜å¥½ã€‚è¿™é‡Œè®°å½•ä¸€ä¸‹æ¯”è¾ƒç«çš„vllmä¸­æå‡æ¨ç†é€Ÿåº¦çš„ä¸€äº›å…³é”®ä»£ç ã€‚\n1. What is vLLMï¼Ÿ vLLMæ˜¯å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿæ¡†æ¶ã€‚ä¸»è¦åœ¨KVcacheç®¡ç†ä¸­é‡‡ç”¨äº†PageAttentionæŠ€æœ¯ï¼Œæ”¯æŒå¸‚é¢ä¸Šä¸»æµçš„å¼€æºå¤§æ¨¡å‹ï¼Œæ”¯æŒé‡åŒ–ç±»å‹ä¸ºï¼šGPTQ,Â AWQ, INT4, INT8, and FP8\n2. KVcacheç›¸å…³çš„è®¡ç®—ä»£ç  ä½¿ç”¨claude-3.7-sonnet thinkingï¼Œå¯¹vllmæ•´ä¸ªé¡¹ç›®è¿›è¡Œæé—®ã€‚\nä¸ºäº†æ›´å¥½ä¸¾ä¾‹ï¼Œä¸‹è½½äº†deepseek-v3-0324ç‰ˆæœ¬çš„config.jsonï¼Œä»£å…¥é¡¹ç›®è¿›è¡Œæé—®ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 { \"architectures\": [ \"DeepseekV3ForCausalLM\" ], \"attention_bias\": false, \"attention_dropout\": 0.0, \"auto_map\": { \"AutoConfig\": \"configuration_deepseek.DeepseekV3Config\", \"AutoModel\": \"modeling_deepseek.DeepseekV3Model\", \"AutoModelForCausalLM\": \"modeling_deepseek.DeepseekV3ForCausalLM\" }, \"aux_loss_alpha\": 0.001, \"bos_token_id\": 0, \"eos_token_id\": 1, \"ep_size\": 1, \"first_k_dense_replace\": 3, \"hidden_act\": \"silu\", \"hidden_size\": 7168, \"initializer_range\": 0.02, \"intermediate_size\": 18432, \"kv_lora_rank\": 512, \"max_position_embeddings\": 163840, \"model_type\": \"deepseek_v3\", \"moe_intermediate_size\": 2048, \"moe_layer_freq\": 1, \"n_group\": 8, \"n_routed_experts\": 256, \"n_shared_experts\": 1, \"norm_topk_prob\": true, \"num_attention_heads\": 128, \"num_experts_per_tok\": 8, \"num_hidden_layers\": 61, \"num_key_value_heads\": 128, \"num_nextn_predict_layers\": 1, \"pretraining_tp\": 1,æ¨¡å‹ä¸­Transformerå±‚çš„æ•°é‡ã€‚æ›´å¤šçš„å±‚æ•°ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ›´æ·±å±‚æ¬¡çš„ç‰¹å¾å’Œå…³ç³»ï¼Œä½†ä¹Ÿå¢åŠ äº†æ¨¡å‹çš„æ·±åº¦å’Œè®¡ç®—æˆæœ¬ã€‚ \"q_lora_rank\": 1536, \"qk_nope_head_dim\": 128, \"qk_rope_head_dim\": 64, \"quantization_config\": { \"activation_scheme\": \"dynamic\", \"fmt\": \"e4m3\", \"quant_method\": \"fp8\", \"weight_block_size\": [ 128, 128 ] }, \"rms_norm_eps\": 1e-06, \"rope_scaling\": { \"beta_fast\": 32, \"beta_slow\": 1, \"factor\": 40, \"mscale\": 1.0, \"mscale_all_dim\": 1.0, \"original_max_position_embeddings\": 4096, \"type\": \"yarn\" }, \"rope_theta\": 10000, \"routed_scaling_factor\": 2.5, \"scoring_func\": \"sigmoid\", \"seq_aux\": true, \"tie_word_embeddings\": false, \"topk_group\": 4, \"topk_method\": \"noaux_tc\", \"torch_dtype\": \"bfloat16\", \"transformers_version\": \"4.46.3\", \"use_cache\": true, \"v_head_dim\": 128, \"vocab_size\": 129280 } è¯¥æ–‡ä»¶ä¸­çš„å…³é”®ä¿¡æ¯ä¸ºï¼š\n2.1 DeepSeek-V1çš„KVcacheæ˜¯å¦‚ä½•è®¡ç®—çš„ï¼Ÿ 2.1.1 æ¨¡å‹å‚æ•°åˆ†æ ä»æä¾›çš„config.jsonæ–‡ä»¶ä¸­æå–çš„å…³é”®å‚æ•°ï¼š\nhidden_size: 7168 num_attention_heads: 128Â (Qå¤´æ•°é‡) num_key_value_heads: 128Â (KVå¤´æ•°é‡ï¼Œæ— MHAç»“æ„) num_hidden_layers: 61Â (Transformerå±‚æ•°) max_position_embeddings: 163840 (æœ€å¤§ä½ç½®åµŒå…¥ï¼Œè¡¨ç¤ºæ”¯æŒçš„æœ€å¤§åºåˆ—é•¿åº¦) torch_dtype: â€œbfloat16â€ (æ¨¡å‹å‚æ•°æ•°æ®ç±»å‹) 2.1.2 KVç¼“å­˜æ˜¾å­˜è®¡ç®— åŸºç¡€å‚æ•°è®¡ç®—\nhead_size = hidden_size / num_attention_heads = 7168 / 128 = 56\næ•°æ®ç±»å‹å¤§å° = bfloat16 = 2å­—èŠ‚ å•ä¸ªæ³¨æ„åŠ›å±‚çš„KVcacheè®¡ç®—\nkey cache size = num_key_value_heads * head_size = 128 * 56 = 7168\nvalue cache size = key cache size = 7168\nå•å±‚å•tokençš„KVç¼“å­˜å¤§å° = (keyç¼“å­˜é¡¹ + valueç¼“å­˜é¡¹) * dtype = (7168 + 7168) * 2 = 28672 â‰ˆ 28kb å…¨æ¨¡å‹æœ€å¤§KVç¼“å­˜è®¡ç®—\nå…¨æ¨¡å‹å•tokençš„KVç¼“å­˜å¤§å° = å•å±‚tokençš„KVç¼“å­˜ * æ¨¡å‹å±‚æ•° = 28kb * 61 = 1708kb â‰ˆ 1.67MB\næœ€å¤§åºåˆ—é•¿åº¦ä¸‹çš„KVç¼“å­˜å¤§å° = å…¨æ¨¡å‹å•tokençš„KVç¼“å­˜å¤§å° * æœ€å¤§åºåˆ—é•¿åº¦ = 273612.8MB â‰ˆ 267.2GB æŒ‰å—åˆ†é…è®¡ç®—\nå¦‚æœä½¿ç”¨vLLMçš„åˆ†å—æœºåˆ¶ï¼Œå‡è®¾block_size=16ï¼š\næ¯ä¸ªå—å¤§å° = æ•°æ®ç±»å‹å¤§å° * æ³¨æ„åŠ›å±‚æ•° * block_size * (key_cache_entry + value_cache_entry) = 2 * 61 * 16 * (7168+7168) â‰ˆ 27.9MB éœ€è¦å—çš„æ•°é‡ = æœ€å¤§åºåˆ—é•¿åº¦ / block_size = 163840 / 16 = 10240å— æ€»æ˜¾å­˜ = æ¯ä¸ªå—å¤§å° * éœ€è¦çš„å—æ•°é‡ = 27.9MB * 10240 â‰ˆ 286GB å®é™…åº”ç”¨è€ƒè™‘ å®é™…ä½¿ç”¨æ—¶å¯èƒ½ä¸ä¼šç”¨æœ€å¤§çš„åºåˆ—é•¿åº¦ï¼Œå¸¸è§çš„è®¾ç½®ä¸º4K - 32K ä¸åŒçš„block_sizeçš„é€‰æ‹©ä¼šå½±å“æ˜¾å­˜ä½¿ç”¨æ•ˆç‡ ä¾‹å¦‚ï¼Œå¦‚æœä½¿ç”¨8Kçš„åºåˆ—é•¿åº¦: KVç¼“å­˜ = 1.67MB * 8192 â‰ˆ 13.7GB 2.1.3 è®¡ç®—KVcacheä»£ç çš„ä½ç½® åœ¨0.7.2ç‰ˆæœ¬ä¸­ï¼Œvllm\\worker\\worker.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 @torch.inference_mode() def determine_num_available_blocks(self) -\u003e Tuple[int, int]: \"\"\"ç¡®å®šå¯ç”¨çš„KVç¼“å­˜å—æ•°é‡ã€‚ è¯¥æ–¹æ³•ä¼šé¦–å…ˆå¯¹ç°æœ‰å†…å­˜ä½¿ç”¨æƒ…å†µè¿›è¡Œåˆ†æ,ç„¶åè®¡ç®—åœ¨å‰©ä½™å¯ç”¨å†…å­˜ä¸‹å¯ä»¥åˆ†é…çš„æœ€å¤§GPUå’ŒCPUå—æ•°é‡ã€‚ ä¸»è¦æ­¥éª¤: 1. æ¸…ç©ºGPUç¼“å­˜å¹¶é‡ç½®å†…å­˜ç»Ÿè®¡ä¿¡æ¯ 2. æ‰§è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­æ¥åˆ†ææ¨¡å‹çš„å†…å­˜ä½¿ç”¨æƒ…å†µ 3. æ ¹æ®GPUå†…å­˜åˆ©ç”¨ç‡å’Œå¯ç”¨å†…å­˜è®¡ç®—å¯åˆ†é…çš„KVç¼“å­˜å—æ•°é‡ 4. è®°å½•è¯¦ç»†çš„å†…å­˜ä½¿ç”¨æƒ…å†µ Returns: Tuple[int, int]: è¿”å›(GPUå—æ•°é‡, CPUå—æ•°é‡)çš„å…ƒç»„ \"\"\" # æ¸…ç©ºGPUç¼“å­˜å¹¶é‡ç½®å†…å­˜ç»Ÿè®¡ä¿¡æ¯ torch.cuda.empty_cache() torch.cuda.reset_peak_memory_stats() # è·å–å½“å‰ç©ºé—²å†…å­˜å’Œæ€»GPUå†…å­˜ free_memory_pre_profile, total_gpu_memory = torch.cuda.mem_get_info() # ä½¿ç”¨è™šæ‹Ÿè¾“å…¥æ‰§è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­,åˆ†ææ¨¡å‹å†…å­˜ä½¿ç”¨æƒ…å†µ with memory_profiling( self.baseline_snapshot, weights_memory=self.model_runner.model_memory_usage) as result: self.model_runner.profile_run() # éªŒè¯å†…å­˜å ç”¨æ˜¯å¦å¢åŠ  self._assert_memory_footprint_increased_during_profiling() # è®¡ç®—å½“å‰å®ä¾‹å¯ç”¨çš„æ€»å†…å­˜ memory_for_current_instance = total_gpu_memory * \\ self.cache_config.gpu_memory_utilization # è®¡ç®—å¯ç”¨äºKVç¼“å­˜çš„å†…å­˜ available_kv_cache_memory = (memory_for_current_instance - result.non_kv_cache_memory) # è®¡ç®—å¯åˆ†é…çš„å—æ•°é‡ cache_block_size = self.get_cache_block_size_bytes() if cache_block_size == 0: num_gpu_blocks = 0 num_cpu_blocks = 0 else: # æ ¹æ®å¯ç”¨å†…å­˜è®¡ç®—GPUå’ŒCPUå—æ•°é‡ num_gpu_blocks = int(available_kv_cache_memory // cache_block_size) num_cpu_blocks = int(self.cache_config.swap_space_bytes // cache_block_size) num_gpu_blocks = max(num_gpu_blocks, 0) num_cpu_blocks = max(num_cpu_blocks, 0) # æ„å»ºè¯¦ç»†çš„å†…å­˜ä½¿ç”¨æƒ…å†µæ—¥å¿— msg = (f\"Memory profiling takes {result.profile_time:.2f} seconds\\n\" \"the current vLLM instance can use \" \"total_gpu_memory \" f\"({(total_gpu_memory / GiB_bytes):.2f}GiB)\" \" x gpu_memory_utilization \" f\"({self.cache_config.gpu_memory_utilization:.2f})\" f\" = {(memory_for_current_instance / GiB_bytes):.2f}GiB\\n\" \"model weights take \" f\"{(result.weights_memory / GiB_bytes):.2f}GiB;\" \" non_torch_memory takes \" f\"{(result.non_torch_increase / GiB_bytes):.2f}GiB;\" \" PyTorch activation peak memory takes \" f\"{(result.torch_peak_increase / GiB_bytes):.2f}GiB;\" \" the rest of the memory reserved for KV Cache is \" f\"{(available_kv_cache_memory / GiB_bytes):.2f}GiB.\") logger.info(msg) # Final cleanup gc.collect() return num_gpu_blocks, num_cpu_blocks 2.2 åœ¨vLLMä¸­å®ç°PageAttentionçš„ä»£ç åœ¨å“ªé‡Œï¼Ÿ å…³äºPageAttentionæŠ€æœ¯çš„å®ç°ï¼Œå®ƒä¸»è¦åœ¨ä»¥ä¸‹æ–‡ä»¶ä¸­ï¼š\nvllm/attention/ops/paged_attn.pyï¼šåŒ…å«PagedAttentionç±»ï¼Œæä¾›KVç¼“å­˜å½¢çŠ¶ã€åˆ†å‰²å’Œå†™å…¥ç­‰æ“ä½œçš„æ¥å£ vllm/_custom_ops.pyï¼šåŒ…å«paged_attention_v1å‡½æ•°ï¼Œè¿æ¥åˆ°C++åº•å±‚å®ç° csrc/attention/attention_kernels.cuï¼šåŒ…å«PageAttentionçš„CUDAå†…æ ¸å®ç° docs/source/design/kernel/paged_attention.mdï¼šè¯¦ç»†è§£é‡Šäº†PageAttentionçš„è®¾è®¡å’Œå®ç°åŸç† PageAttentionæ˜¯vLLMçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œé€šè¿‡å°†KVç¼“å­˜å­˜å‚¨åœ¨ä¸è¿ç»­çš„å†…å­˜å—ä¸­ï¼Œå®ç°äº†é«˜æ•ˆçš„å†…å­˜ç®¡ç†ã€‚è¿™äº›å†…å­˜å—å¯ä»¥æ ¹æ®éœ€è¦åŠ¨æ€åˆ†é…å’Œé‡Šæ”¾ï¼Œä½¿å¾—å•ä¸ªGPUèƒ½å¤ŸæœåŠ¡æ›´å¤šå¹¶å‘è¯·æ±‚ã€‚è¯¥æŠ€æœ¯çš„å…³é”®ç‰¹ç‚¹æ˜¯é€šè¿‡åˆ†é¡µæœºåˆ¶é¿å…äº†æ˜¾å­˜ç¢ç‰‡ï¼Œå¹¶æ”¯æŒé«˜æ•ˆçš„ä¸Šä¸‹æ–‡å¤„ç†ã€‚ 3. éªŒè¯ ä½¿ç”¨4090DåŸºäºvllmå¯ç”¨é»˜è®¤å‚æ•°è¿›è¡Œæ¨ç†ã€‚æŸ¥çœ‹å¯åŠ¨æœåŠ¡çš„æ—¥å¿—å†…å®¹ã€‚\n3.1 æ¨¡å‹æ—¥å¿— 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 INFO 04-14 06:00:50 [__init__.py:239] Automatically detected platform cuda. INFO 04-14 06:00:52 [api_server.py:1034] vLLM API server version 0.8.3 INFO 04-14 06:00:52 [api_server.py:1035] args: Namespace(subparser='serve', model_tag='/data/DeepSeek-R1-Distill-Qwen-1.5B', config='', host=None, port=8000, uvicorn_log_level='info', disable_uvicorn_access_log=False, allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, enable_ssl_refresh=False, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='/data/DeepSeek-R1-Distill-Qwen-1.5B', task='auto', tokenizer=None, hf_config_path=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, download_dir=None, load_format='auto', config_format=","wordCount":"2323","inLanguage":"en","datePublished":"2025-04-14T00:38:00Z","dateModified":"2025-04-14T09:00:00Z","author":{"@type":"Person","name":"Pan Binghong"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://Pan-Binghong.github.io/daily-learning/ai/learning-vll-0.7.2-with-cursor/"},"publisher":{"@type":"Organization","name":"æˆ‘çš„åšå®¢","logo":{"@type":"ImageObject","url":"https://Pan-Binghong.github.io/daily-learning/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://Pan-Binghong.github.io/daily-learning/ accesskey=h title="æˆ‘çš„åšå®¢ (Alt + H)">æˆ‘çš„åšå®¢</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://Pan-Binghong.github.io/daily-learning/ title=é¦–é¡µ><span>é¦–é¡µ</span></a></li><li><a href=https://Pan-Binghong.github.io/daily-learning/ai/ title=AI><span>AI</span></a></li><li><a href=https://Pan-Binghong.github.io/daily-learning/knowledge/ title=çŸ¥è¯†åº“><span>çŸ¥è¯†åº“</span></a></li><li><a href=https://Pan-Binghong.github.io/daily-learning/backend/ title=åç«¯><span>åç«¯</span></a></li><li><a href=https://Pan-Binghong.github.io/daily-learning/devops/ title=DevOps><span>DevOps</span></a></li><li><a href=https://Pan-Binghong.github.io/daily-learning/other/ title=å…¶ä»–><span>å…¶ä»–</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Learning vLL (0.7.2) with Cursor</h1><div class=post-meta><span title='2025-04-14 00:38:00 +0000 UTC'>April 14, 2025</span>&nbsp;Â·&nbsp;<span>Pan Binghong</span></div></header><div class=post-content><blockquote><p>ğŸ’¡ ä¹‹å‰ä¸€ç›´ç”¨cursorè¾…åŠ©å†™ä»£ç ï¼Œçªç„¶è¯•äº†ä¸€ä¸‹å»åˆ©ç”¨cursoræ¥å­¦ä»£ç ï¼Œå‘ç°æ•ˆæœå˜å˜å¥½ã€‚è¿™é‡Œè®°å½•ä¸€ä¸‹æ¯”è¾ƒç«çš„vllmä¸­æå‡æ¨ç†é€Ÿåº¦çš„ä¸€äº›å…³é”®ä»£ç ã€‚</p></blockquote><h1 id=1-what-is-vllm>1. What is vLLMï¼Ÿ<a hidden class=anchor aria-hidden=true href=#1-what-is-vllm>#</a></h1><p><img loading=lazy src="https://prod-files-secure.s3.us-west-2.amazonaws.com/fc187c04-cf34-444f-b5f2-bdcdfad76660/ccc90792-56ef-4142-8b21-8ecb32787141/image.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB4667YCEVZW6%2F20251106%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20251106T013103Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjENL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIAJmQQ7mWsxzpJ6otXyMC9d9z3VcJ1Cqc6mqDB4YYEBLAiEAvAcaFpnhw1lH5aWvAtrUlv%2BxkIUtoR43gpU0OKtQ2SkqiAQImv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw2Mzc0MjMxODM4MDUiDOuphhw75zjnLjShdircA71aqmiGCBK7mWpFPe5yK6vH6iD9kmenheve3OPlszSJLj5dShokJxdMFzAYgU6OOU0yPmNNK3MMk77UxQZ3RkPoN9mpN8jlPCTtSc8q0xUBMsrCwQ4YsjyTOC4geMN3ESykY4HYWw8I%2BmPohQmpUgTFNPAv4IkrLDdFptYB0pcDVbY8K5lkE6rHJZChlzNBm3uNFQY9axt7XwopTwsAoxAEympoGXnIDMNNMn11iN6dJjyTE3jc%2BFfcnHBQ15eFH%2FZqTxuLUg1rHrJiRzKiQnWrTy4XsA%2BGnTvPaBE%2FXKTCgmSyZUhkhisytIqSa5Ul0oh%2BTiXIO%2BfxReCr66G57e6vDNMDOupPoT92nDav0MAP8v0GwzsYa2VWg1WT9uqYEJtfwiYAGAT0NsH69p4s0c0yozq0lqLmWop6vk493jICw33dpSUsrMDwa%2F9p1nvEjgr%2FNl45mExCBOPVy61eIbGobXH%2Fd9nHACZrTHyavENIlrx8SJ4rA2dnCjkwEkYL%2B1tarCVCRWaJmrJ%2BfeFcUoV0fpZ2EOxo74pluo6pS3a%2FqE938Y1%2FOQ7BA2nNYk0v1ulgzrNwStGl%2FJVGWV%2BR7v7zArQB86AxH3Z0qWWQXye1ZZ3AOVmfHrOBtVSJMPDxr8gGOqUBeUSQ5o9f8zYjB3B3CaKxdFKtMmTtUcnp%2FJ5%2BnhGkBprJ8I%2BY7YxZsqzqnNyFBnR0cGDXU%2BR8u7W2GooAX%2FLaqEnwWBigx5%2BwHmOeIh3t%2FH5V8ZQSI8G7RKTc%2BS1hHVoYkkDPtQ%2F71INnThJuIe%2FXi%2BoRF6t%2FvuJmiTyNDEfHlLhMrt0uL69qK21UP6%2FLHVE2e2uMxbFKNdJhOJFqm1QEgKMxp1ls&X-Amz-Signature=db91b35c675128b6a5085b17fce3ffb7110b93d43fe44b3e5f47cec4502cc4dd&X-Amz-SignedHeaders=host&x-amz-checksum-mode=ENABLED&x-id=GetObject"></p><p>vLLMæ˜¯å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿæ¡†æ¶ã€‚ä¸»è¦åœ¨KVcacheç®¡ç†ä¸­é‡‡ç”¨äº†PageAttentionæŠ€æœ¯ï¼Œæ”¯æŒå¸‚é¢ä¸Šä¸»æµçš„å¼€æºå¤§æ¨¡å‹ï¼Œæ”¯æŒé‡åŒ–ç±»å‹ä¸ºï¼šGPTQ,Â AWQ, INT4, INT8, and FP8</p><hr><h1 id=2-kvcacheç›¸å…³çš„è®¡ç®—ä»£ç >2. KVcacheç›¸å…³çš„è®¡ç®—ä»£ç <a hidden class=anchor aria-hidden=true href=#2-kvcacheç›¸å…³çš„è®¡ç®—ä»£ç >#</a></h1><p>ä½¿ç”¨claude-3.7-sonnet thinkingï¼Œå¯¹vllmæ•´ä¸ªé¡¹ç›®è¿›è¡Œæé—®ã€‚</p><p><img loading=lazy src="https://prod-files-secure.s3.us-west-2.amazonaws.com/fc187c04-cf34-444f-b5f2-bdcdfad76660/cb54e376-a945-4f40-a5b9-ff4fc10e9fc2/image.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB4667YCEVZW6%2F20251106%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20251106T013103Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjENL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIAJmQQ7mWsxzpJ6otXyMC9d9z3VcJ1Cqc6mqDB4YYEBLAiEAvAcaFpnhw1lH5aWvAtrUlv%2BxkIUtoR43gpU0OKtQ2SkqiAQImv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw2Mzc0MjMxODM4MDUiDOuphhw75zjnLjShdircA71aqmiGCBK7mWpFPe5yK6vH6iD9kmenheve3OPlszSJLj5dShokJxdMFzAYgU6OOU0yPmNNK3MMk77UxQZ3RkPoN9mpN8jlPCTtSc8q0xUBMsrCwQ4YsjyTOC4geMN3ESykY4HYWw8I%2BmPohQmpUgTFNPAv4IkrLDdFptYB0pcDVbY8K5lkE6rHJZChlzNBm3uNFQY9axt7XwopTwsAoxAEympoGXnIDMNNMn11iN6dJjyTE3jc%2BFfcnHBQ15eFH%2FZqTxuLUg1rHrJiRzKiQnWrTy4XsA%2BGnTvPaBE%2FXKTCgmSyZUhkhisytIqSa5Ul0oh%2BTiXIO%2BfxReCr66G57e6vDNMDOupPoT92nDav0MAP8v0GwzsYa2VWg1WT9uqYEJtfwiYAGAT0NsH69p4s0c0yozq0lqLmWop6vk493jICw33dpSUsrMDwa%2F9p1nvEjgr%2FNl45mExCBOPVy61eIbGobXH%2Fd9nHACZrTHyavENIlrx8SJ4rA2dnCjkwEkYL%2B1tarCVCRWaJmrJ%2BfeFcUoV0fpZ2EOxo74pluo6pS3a%2FqE938Y1%2FOQ7BA2nNYk0v1ulgzrNwStGl%2FJVGWV%2BR7v7zArQB86AxH3Z0qWWQXye1ZZ3AOVmfHrOBtVSJMPDxr8gGOqUBeUSQ5o9f8zYjB3B3CaKxdFKtMmTtUcnp%2FJ5%2BnhGkBprJ8I%2BY7YxZsqzqnNyFBnR0cGDXU%2BR8u7W2GooAX%2FLaqEnwWBigx5%2BwHmOeIh3t%2FH5V8ZQSI8G7RKTc%2BS1hHVoYkkDPtQ%2F71INnThJuIe%2FXi%2BoRF6t%2FvuJmiTyNDEfHlLhMrt0uL69qK21UP6%2FLHVE2e2uMxbFKNdJhOJFqm1QEgKMxp1ls&X-Amz-Signature=7b6b5395096912aab6190527ef8e05e3dbe3f26c9fb8b41fc690e9298b0765f9&X-Amz-SignedHeaders=host&x-amz-checksum-mode=ENABLED&x-id=GetObject"></p><p>ä¸ºäº†æ›´å¥½ä¸¾ä¾‹ï¼Œä¸‹è½½äº†deepseek-v3-0324ç‰ˆæœ¬çš„config.jsonï¼Œä»£å…¥é¡¹ç›®è¿›è¡Œæé—®ã€‚</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">64
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">65
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">66
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">67
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">68
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">69
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">70
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">71
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;architectures&#34;</span>: [
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;DeepseekV3ForCausalLM&#34;</span>
</span></span><span style=display:flex><span>  ],
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;attention_bias&#34;</span>: <span style=color:#66d9ef>false</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;attention_dropout&#34;</span>: <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;auto_map&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;AutoConfig&#34;</span>: <span style=color:#e6db74>&#34;configuration_deepseek.DeepseekV3Config&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;AutoModel&#34;</span>: <span style=color:#e6db74>&#34;modeling_deepseek.DeepseekV3Model&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;AutoModelForCausalLM&#34;</span>: <span style=color:#e6db74>&#34;modeling_deepseek.DeepseekV3ForCausalLM&#34;</span>
</span></span><span style=display:flex><span>  },
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;aux_loss_alpha&#34;</span>: <span style=color:#ae81ff>0.001</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;bos_token_id&#34;</span>: <span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;eos_token_id&#34;</span>: <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;ep_size&#34;</span>: <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;first_k_dense_replace&#34;</span>: <span style=color:#ae81ff>3</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;hidden_act&#34;</span>: <span style=color:#e6db74>&#34;silu&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;hidden_size&#34;</span>: <span style=color:#ae81ff>7168</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;initializer_range&#34;</span>: <span style=color:#ae81ff>0.02</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;intermediate_size&#34;</span>: <span style=color:#ae81ff>18432</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;kv_lora_rank&#34;</span>: <span style=color:#ae81ff>512</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;max_position_embeddings&#34;</span>: <span style=color:#ae81ff>163840</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;model_type&#34;</span>: <span style=color:#e6db74>&#34;deepseek_v3&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;moe_intermediate_size&#34;</span>: <span style=color:#ae81ff>2048</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;moe_layer_freq&#34;</span>: <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;n_group&#34;</span>: <span style=color:#ae81ff>8</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;n_routed_experts&#34;</span>: <span style=color:#ae81ff>256</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;n_shared_experts&#34;</span>: <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;norm_topk_prob&#34;</span>: <span style=color:#66d9ef>true</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;num_attention_heads&#34;</span>: <span style=color:#ae81ff>128</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;num_experts_per_tok&#34;</span>: <span style=color:#ae81ff>8</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;num_hidden_layers&#34;</span>: <span style=color:#ae81ff>61</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;num_key_value_heads&#34;</span>: <span style=color:#ae81ff>128</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;num_nextn_predict_layers&#34;</span>: <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;pretraining_tp&#34;</span>: <span style=color:#ae81ff>1</span>,<span style=color:#960050;background-color:#1e0010>æ¨¡å‹ä¸­Transformerå±‚çš„æ•°é‡ã€‚æ›´å¤šçš„å±‚æ•°ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ›´æ·±å±‚æ¬¡çš„ç‰¹å¾å’Œå…³ç³»ï¼Œä½†ä¹Ÿå¢åŠ äº†æ¨¡å‹çš„æ·±åº¦å’Œè®¡ç®—æˆæœ¬ã€‚</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;q_lora_rank&#34;</span>: <span style=color:#ae81ff>1536</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;qk_nope_head_dim&#34;</span>: <span style=color:#ae81ff>128</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;qk_rope_head_dim&#34;</span>: <span style=color:#ae81ff>64</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;quantization_config&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;activation_scheme&#34;</span>: <span style=color:#e6db74>&#34;dynamic&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;fmt&#34;</span>: <span style=color:#e6db74>&#34;e4m3&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;quant_method&#34;</span>: <span style=color:#e6db74>&#34;fp8&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;weight_block_size&#34;</span>: [
</span></span><span style=display:flex><span>      <span style=color:#ae81ff>128</span>,
</span></span><span style=display:flex><span>      <span style=color:#ae81ff>128</span>
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>  },
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;rms_norm_eps&#34;</span>: <span style=color:#ae81ff>1e-06</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;rope_scaling&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;beta_fast&#34;</span>: <span style=color:#ae81ff>32</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;beta_slow&#34;</span>: <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;factor&#34;</span>: <span style=color:#ae81ff>40</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;mscale&#34;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;mscale_all_dim&#34;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;original_max_position_embeddings&#34;</span>: <span style=color:#ae81ff>4096</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;yarn&#34;</span>
</span></span><span style=display:flex><span>  },
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;rope_theta&#34;</span>: <span style=color:#ae81ff>10000</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;routed_scaling_factor&#34;</span>: <span style=color:#ae81ff>2.5</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;scoring_func&#34;</span>: <span style=color:#e6db74>&#34;sigmoid&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;seq_aux&#34;</span>: <span style=color:#66d9ef>true</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;tie_word_embeddings&#34;</span>: <span style=color:#66d9ef>false</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;topk_group&#34;</span>: <span style=color:#ae81ff>4</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;topk_method&#34;</span>: <span style=color:#e6db74>&#34;noaux_tc&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;torch_dtype&#34;</span>: <span style=color:#e6db74>&#34;bfloat16&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;transformers_version&#34;</span>: <span style=color:#e6db74>&#34;4.46.3&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;use_cache&#34;</span>: <span style=color:#66d9ef>true</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;v_head_dim&#34;</span>: <span style=color:#ae81ff>128</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;vocab_size&#34;</span>: <span style=color:#ae81ff>129280</span>
</span></span><span style=display:flex><span>}
</span></span></code></pre></td></tr></table></div></div><p>è¯¥æ–‡ä»¶ä¸­çš„å…³é”®ä¿¡æ¯ä¸ºï¼š</p><h2 id=21-deepseek-v1çš„kvcacheæ˜¯å¦‚ä½•è®¡ç®—çš„>2.1 DeepSeek-V1çš„KVcacheæ˜¯å¦‚ä½•è®¡ç®—çš„ï¼Ÿ<a hidden class=anchor aria-hidden=true href=#21-deepseek-v1çš„kvcacheæ˜¯å¦‚ä½•è®¡ç®—çš„>#</a></h2><h3 id=211-æ¨¡å‹å‚æ•°åˆ†æ>2.1.1 æ¨¡å‹å‚æ•°åˆ†æ<a hidden class=anchor aria-hidden=true href=#211-æ¨¡å‹å‚æ•°åˆ†æ>#</a></h3><p>ä»æä¾›çš„config.jsonæ–‡ä»¶ä¸­æå–çš„å…³é”®å‚æ•°ï¼š</p><ul><li>hidden_size: 7168</li><li>num_attention_heads: 128Â (Qå¤´æ•°é‡)</li><li>num_key_value_heads: 128Â (KVå¤´æ•°é‡ï¼Œæ— MHAç»“æ„)</li><li>num_hidden_layers: 61Â (Transformerå±‚æ•°)</li><li>max_position_embeddings: 163840 (æœ€å¤§ä½ç½®åµŒå…¥ï¼Œè¡¨ç¤ºæ”¯æŒçš„æœ€å¤§åºåˆ—é•¿åº¦)</li><li>torch_dtype: &ldquo;bfloat16&rdquo; (æ¨¡å‹å‚æ•°æ•°æ®ç±»å‹)</li></ul><hr><h3 id=212-kvç¼“å­˜æ˜¾å­˜è®¡ç®—>2.1.2 KVç¼“å­˜æ˜¾å­˜è®¡ç®—<a hidden class=anchor aria-hidden=true href=#212-kvç¼“å­˜æ˜¾å­˜è®¡ç®—>#</a></h3><p>åŸºç¡€å‚æ•°è®¡ç®—</p><ul><li><p>head_size = hidden_size / num_attention_heads = 7168 / 128 = 56</p></li><li><p>æ•°æ®ç±»å‹å¤§å° = bfloat16 = 2å­—èŠ‚
å•ä¸ªæ³¨æ„åŠ›å±‚çš„KVcacheè®¡ç®—</p></li><li><p>key cache size = num_key_value_heads * head_size = 128 * 56 = 7168</p></li><li><p>value cache size = key cache size = 7168</p></li><li><p>å•å±‚å•tokençš„KVç¼“å­˜å¤§å° = (keyç¼“å­˜é¡¹ + valueç¼“å­˜é¡¹) * dtype = (7168 + 7168) * 2 = 28672 â‰ˆ 28kb
å…¨æ¨¡å‹æœ€å¤§KVç¼“å­˜è®¡ç®—</p></li><li><p>å…¨æ¨¡å‹å•tokençš„KVç¼“å­˜å¤§å° = å•å±‚tokençš„KVç¼“å­˜ * æ¨¡å‹å±‚æ•° = 28kb * 61 = 1708kb â‰ˆ 1.67MB</p></li><li><p>æœ€å¤§åºåˆ—é•¿åº¦ä¸‹çš„KVç¼“å­˜å¤§å° = å…¨æ¨¡å‹å•tokençš„KVç¼“å­˜å¤§å° * æœ€å¤§åºåˆ—é•¿åº¦ = 273612.8MB â‰ˆ 267.2GB
æŒ‰å—åˆ†é…è®¡ç®—</p></li></ul><p>å¦‚æœä½¿ç”¨vLLMçš„åˆ†å—æœºåˆ¶ï¼Œå‡è®¾block_size=16ï¼š</p><ul><li>æ¯ä¸ªå—å¤§å° = æ•°æ®ç±»å‹å¤§å° * æ³¨æ„åŠ›å±‚æ•° * block_size * (key_cache_entry + value_cache_entry) = 2 * 61 * 16 * (7168+7168) â‰ˆ 27.9MB</li><li>éœ€è¦å—çš„æ•°é‡ = æœ€å¤§åºåˆ—é•¿åº¦ / block_size = 163840 / 16 = 10240å—</li><li>æ€»æ˜¾å­˜ = æ¯ä¸ªå—å¤§å° * éœ€è¦çš„å—æ•°é‡ = 27.9MB * 10240 â‰ˆ 286GB
å®é™…åº”ç”¨è€ƒè™‘</li></ul><ol><li>å®é™…ä½¿ç”¨æ—¶å¯èƒ½ä¸ä¼šç”¨æœ€å¤§çš„åºåˆ—é•¿åº¦ï¼Œå¸¸è§çš„è®¾ç½®ä¸º4K - 32K</li><li>ä¸åŒçš„block_sizeçš„é€‰æ‹©ä¼šå½±å“æ˜¾å­˜ä½¿ç”¨æ•ˆç‡
ä¾‹å¦‚ï¼Œå¦‚æœä½¿ç”¨8Kçš„åºåˆ—é•¿åº¦:</li></ol><ul><li>KVç¼“å­˜ = 1.67MB * 8192 â‰ˆ 13.7GB</li></ul><hr><h3 id=213-è®¡ç®—kvcacheä»£ç çš„ä½ç½®>2.1.3 è®¡ç®—KVcacheä»£ç çš„ä½ç½®<a hidden class=anchor aria-hidden=true href=#213-è®¡ç®—kvcacheä»£ç çš„ä½ç½®>#</a></h3><p>åœ¨0.7.2ç‰ˆæœ¬ä¸­ï¼Œvllm\worker\worker.py</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">64
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">65
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">66
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">67
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">68
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">69
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">70
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">71
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">72
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">73
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#a6e22e>@torch.inference_mode</span>()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>determine_num_available_blocks</span>(self) <span style=color:#f92672>-&gt;</span> Tuple[int, int]:
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;ç¡®å®šå¯ç”¨çš„KVç¼“å­˜å—æ•°é‡ã€‚
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        è¯¥æ–¹æ³•ä¼šé¦–å…ˆå¯¹ç°æœ‰å†…å­˜ä½¿ç”¨æƒ…å†µè¿›è¡Œåˆ†æ,ç„¶åè®¡ç®—åœ¨å‰©ä½™å¯ç”¨å†…å­˜ä¸‹å¯ä»¥åˆ†é…çš„æœ€å¤§GPUå’ŒCPUå—æ•°é‡ã€‚
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        ä¸»è¦æ­¥éª¤:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        1. æ¸…ç©ºGPUç¼“å­˜å¹¶é‡ç½®å†…å­˜ç»Ÿè®¡ä¿¡æ¯
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        2. æ‰§è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­æ¥åˆ†ææ¨¡å‹çš„å†…å­˜ä½¿ç”¨æƒ…å†µ
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        3. æ ¹æ®GPUå†…å­˜åˆ©ç”¨ç‡å’Œå¯ç”¨å†…å­˜è®¡ç®—å¯åˆ†é…çš„KVç¼“å­˜å—æ•°é‡
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        4. è®°å½•è¯¦ç»†çš„å†…å­˜ä½¿ç”¨æƒ…å†µ
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Returns:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            Tuple[int, int]: è¿”å›(GPUå—æ•°é‡, CPUå—æ•°é‡)çš„å…ƒç»„
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># æ¸…ç©ºGPUç¼“å­˜å¹¶é‡ç½®å†…å­˜ç»Ÿè®¡ä¿¡æ¯</span>
</span></span><span style=display:flex><span>        torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>empty_cache()
</span></span><span style=display:flex><span>        torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>reset_peak_memory_stats()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># è·å–å½“å‰ç©ºé—²å†…å­˜å’Œæ€»GPUå†…å­˜</span>
</span></span><span style=display:flex><span>        free_memory_pre_profile, total_gpu_memory <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>mem_get_info()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># ä½¿ç”¨è™šæ‹Ÿè¾“å…¥æ‰§è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­,åˆ†ææ¨¡å‹å†…å­˜ä½¿ç”¨æƒ…å†µ</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>with</span> memory_profiling(
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>baseline_snapshot,
</span></span><span style=display:flex><span>                weights_memory<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>model_runner<span style=color:#f92672>.</span>model_memory_usage) <span style=color:#66d9ef>as</span> result:
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>model_runner<span style=color:#f92672>.</span>profile_run()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># éªŒè¯å†…å­˜å ç”¨æ˜¯å¦å¢åŠ </span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_assert_memory_footprint_increased_during_profiling()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># è®¡ç®—å½“å‰å®ä¾‹å¯ç”¨çš„æ€»å†…å­˜</span>
</span></span><span style=display:flex><span>        memory_for_current_instance <span style=color:#f92672>=</span> total_gpu_memory <span style=color:#f92672>*</span> \
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>cache_config<span style=color:#f92672>.</span>gpu_memory_utilization
</span></span><span style=display:flex><span>        <span style=color:#75715e># è®¡ç®—å¯ç”¨äºKVç¼“å­˜çš„å†…å­˜</span>
</span></span><span style=display:flex><span>        available_kv_cache_memory <span style=color:#f92672>=</span> (memory_for_current_instance <span style=color:#f92672>-</span>
</span></span><span style=display:flex><span>                                     result<span style=color:#f92672>.</span>non_kv_cache_memory)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># è®¡ç®—å¯åˆ†é…çš„å—æ•°é‡</span>
</span></span><span style=display:flex><span>        cache_block_size <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>get_cache_block_size_bytes()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> cache_block_size <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>            num_gpu_blocks <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>            num_cpu_blocks <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>            <span style=color:#75715e># æ ¹æ®å¯ç”¨å†…å­˜è®¡ç®—GPUå’ŒCPUå—æ•°é‡</span>
</span></span><span style=display:flex><span>            num_gpu_blocks <span style=color:#f92672>=</span> int(available_kv_cache_memory <span style=color:#f92672>//</span> cache_block_size)
</span></span><span style=display:flex><span>            num_cpu_blocks <span style=color:#f92672>=</span> int(self<span style=color:#f92672>.</span>cache_config<span style=color:#f92672>.</span>swap_space_bytes <span style=color:#f92672>//</span>
</span></span><span style=display:flex><span>                                 cache_block_size)
</span></span><span style=display:flex><span>        num_gpu_blocks <span style=color:#f92672>=</span> max(num_gpu_blocks, <span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        num_cpu_blocks <span style=color:#f92672>=</span> max(num_cpu_blocks, <span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># æ„å»ºè¯¦ç»†çš„å†…å­˜ä½¿ç”¨æƒ…å†µæ—¥å¿—</span>
</span></span><span style=display:flex><span>        msg <span style=color:#f92672>=</span> (<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Memory profiling takes </span><span style=color:#e6db74>{</span>result<span style=color:#f92672>.</span>profile_time<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> seconds</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>&#34;the current vLLM instance can use &#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>&#34;total_gpu_memory &#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;(</span><span style=color:#e6db74>{</span>(total_gpu_memory <span style=color:#f92672>/</span> GiB_bytes)<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>GiB)&#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>&#34; x gpu_memory_utilization &#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;(</span><span style=color:#e6db74>{</span>self<span style=color:#f92672>.</span>cache_config<span style=color:#f92672>.</span>gpu_memory_utilization<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>)&#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34; = </span><span style=color:#e6db74>{</span>(memory_for_current_instance <span style=color:#f92672>/</span> GiB_bytes)<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>GiB</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>&#34;model weights take &#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>(result<span style=color:#f92672>.</span>weights_memory <span style=color:#f92672>/</span> GiB_bytes)<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>GiB;&#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>&#34; non_torch_memory takes &#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>(result<span style=color:#f92672>.</span>non_torch_increase <span style=color:#f92672>/</span> GiB_bytes)<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>GiB;&#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>&#34; PyTorch activation peak memory takes &#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>(result<span style=color:#f92672>.</span>torch_peak_increase <span style=color:#f92672>/</span> GiB_bytes)<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>GiB;&#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>&#34; the rest of the memory reserved for KV Cache is &#34;</span>
</span></span><span style=display:flex><span>               <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>(available_kv_cache_memory <span style=color:#f92672>/</span> GiB_bytes)<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>GiB.&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        logger<span style=color:#f92672>.</span>info(msg)
</span></span><span style=display:flex><span>        <span style=color:#75715e># Final cleanup</span>
</span></span><span style=display:flex><span>        gc<span style=color:#f92672>.</span>collect()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> num_gpu_blocks, num_cpu_blocks
</span></span></code></pre></td></tr></table></div></div><hr><h2 id=22-åœ¨vllmä¸­å®ç°pageattentionçš„ä»£ç åœ¨å“ªé‡Œ>2.2 åœ¨vLLMä¸­å®ç°PageAttentionçš„ä»£ç åœ¨å“ªé‡Œï¼Ÿ<a hidden class=anchor aria-hidden=true href=#22-åœ¨vllmä¸­å®ç°pageattentionçš„ä»£ç åœ¨å“ªé‡Œ>#</a></h2><p>å…³äºPageAttentionæŠ€æœ¯çš„å®ç°ï¼Œå®ƒä¸»è¦åœ¨ä»¥ä¸‹æ–‡ä»¶ä¸­ï¼š</p><ol><li>vllm/attention/ops/paged_attn.pyï¼šåŒ…å«PagedAttentionç±»ï¼Œæä¾›KVç¼“å­˜å½¢çŠ¶ã€åˆ†å‰²å’Œå†™å…¥ç­‰æ“ä½œçš„æ¥å£</li><li>vllm/_custom_ops.pyï¼šåŒ…å«paged_attention_v1å‡½æ•°ï¼Œè¿æ¥åˆ°C++åº•å±‚å®ç°</li><li>csrc/attention/attention_kernels.cuï¼šåŒ…å«PageAttentionçš„CUDAå†…æ ¸å®ç°</li><li>docs/source/design/kernel/paged_attention.mdï¼šè¯¦ç»†è§£é‡Šäº†PageAttentionçš„è®¾è®¡å’Œå®ç°åŸç†
PageAttentionæ˜¯vLLMçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œé€šè¿‡å°†KVç¼“å­˜å­˜å‚¨åœ¨ä¸è¿ç»­çš„å†…å­˜å—ä¸­ï¼Œå®ç°äº†é«˜æ•ˆçš„å†…å­˜ç®¡ç†ã€‚è¿™äº›å†…å­˜å—å¯ä»¥æ ¹æ®éœ€è¦åŠ¨æ€åˆ†é…å’Œé‡Šæ”¾ï¼Œä½¿å¾—å•ä¸ªGPUèƒ½å¤ŸæœåŠ¡æ›´å¤šå¹¶å‘è¯·æ±‚ã€‚è¯¥æŠ€æœ¯çš„å…³é”®ç‰¹ç‚¹æ˜¯é€šè¿‡åˆ†é¡µæœºåˆ¶é¿å…äº†æ˜¾å­˜ç¢ç‰‡ï¼Œå¹¶æ”¯æŒé«˜æ•ˆçš„ä¸Šä¸‹æ–‡å¤„ç†ã€‚</li></ol><hr><h1 id=3-éªŒè¯>3. éªŒè¯<a hidden class=anchor aria-hidden=true href=#3-éªŒè¯>#</a></h1><p>ä½¿ç”¨4090DåŸºäºvllmå¯ç”¨é»˜è®¤å‚æ•°è¿›è¡Œæ¨ç†ã€‚æŸ¥çœ‹å¯åŠ¨æœåŠ¡çš„æ—¥å¿—å†…å®¹ã€‚</p><h2 id=31-æ¨¡å‹æ—¥å¿—>3.1 æ¨¡å‹æ—¥å¿—<a hidden class=anchor aria-hidden=true href=#31-æ¨¡å‹æ—¥å¿—>#</a></h2><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">61
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>INFO 04-14 06:00:50 <span style=color:#f92672>[</span>__init__.py:239<span style=color:#f92672>]</span> Automatically detected platform cuda.
</span></span><span style=display:flex><span>INFO 04-14 06:00:52 <span style=color:#f92672>[</span>api_server.py:1034<span style=color:#f92672>]</span> vLLM API server version 0.8.3
</span></span><span style=display:flex><span>INFO 04-14 06:00:52 <span style=color:#f92672>[</span>api_server.py:1035<span style=color:#f92672>]</span> args: Namespace<span style=color:#f92672>(</span>subparser<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;serve&#39;</span>, model_tag<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;/data/DeepSeek-R1-Distill-Qwen-1.5B&#39;</span>, config<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;&#39;</span>, host<span style=color:#f92672>=</span>None, port<span style=color:#f92672>=</span>8000, uvicorn_log_level<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;info&#39;</span>, disable_uvicorn_access_log<span style=color:#f92672>=</span>False, allow_credentials<span style=color:#f92672>=</span>False, allowed_origins<span style=color:#f92672>=[</span><span style=color:#e6db74>&#39;*&#39;</span><span style=color:#f92672>]</span>, allowed_methods<span style=color:#f92672>=[</span><span style=color:#e6db74>&#39;*&#39;</span><span style=color:#f92672>]</span>, allowed_headers<span style=color:#f92672>=[</span><span style=color:#e6db74>&#39;*&#39;</span><span style=color:#f92672>]</span>, api_key<span style=color:#f92672>=</span>None, lora_modules<span style=color:#f92672>=</span>None, prompt_adapters<span style=color:#f92672>=</span>None, chat_template<span style=color:#f92672>=</span>None, chat_template_content_format<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>, response_role<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;assistant&#39;</span>, ssl_keyfile<span style=color:#f92672>=</span>None, ssl_certfile<span style=color:#f92672>=</span>None, ssl_ca_certs<span style=color:#f92672>=</span>None, enable_ssl_refresh<span style=color:#f92672>=</span>False, ssl_cert_reqs<span style=color:#f92672>=</span>0, root_path<span style=color:#f92672>=</span>None, middleware<span style=color:#f92672>=[]</span>, return_tokens_as_token_ids<span style=color:#f92672>=</span>False, disable_frontend_multiprocessing<span style=color:#f92672>=</span>False, enable_request_id_headers<span style=color:#f92672>=</span>False, enable_auto_tool_choice<span style=color:#f92672>=</span>False, tool_call_parser<span style=color:#f92672>=</span>None, tool_parser_plugin<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;&#39;</span>, model<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;/data/DeepSeek-R1-Distill-Qwen-1.5B&#39;</span>, task<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>, tokenizer<span style=color:#f92672>=</span>None, hf_config_path<span style=color:#f92672>=</span>None, skip_tokenizer_init<span style=color:#f92672>=</span>False, revision<span style=color:#f92672>=</span>None, code_revision<span style=color:#f92672>=</span>None, tokenizer_revision<span style=color:#f92672>=</span>None, tokenizer_mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>, trust_remote_code<span style=color:#f92672>=</span>False, allowed_local_media_path<span style=color:#f92672>=</span>None, download_dir<span style=color:#f92672>=</span>None, load_format<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>, config_format<span style=color:#f92672>=</span>&lt;ConfigFormat.AUTO: <span style=color:#e6db74>&#39;auto&#39;</span>&gt;, dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>, kv_cache_dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>, max_model_len<span style=color:#f92672>=</span>None, guided_decoding_backend<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;xgrammar&#39;</span>, logits_processor_pattern<span style=color:#f92672>=</span>None, model_impl<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>, distributed_executor_backend<span style=color:#f92672>=</span>None, pipeline_parallel_size<span style=color:#f92672>=</span>1, tensor_parallel_size<span style=color:#f92672>=</span>1, data_parallel_size<span style=color:#f92672>=</span>1, enable_expert_parallel<span style=color:#f92672>=</span>False, max_parallel_loading_workers<span style=color:#f92672>=</span>None, ray_workers_use_nsight<span style=color:#f92672>=</span>False, block_size<span style=color:#f92672>=</span>None, enable_prefix_caching<span style=color:#f92672>=</span>None, prefix_caching_hash_algo<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;builtin&#39;</span>, disable_sliding_window<span style=color:#f92672>=</span>False, use_v2_block_manager<span style=color:#f92672>=</span>True, num_lookahead_slots<span style=color:#f92672>=</span>0, seed<span style=color:#f92672>=</span>None, swap_space<span style=color:#f92672>=</span>4, cpu_offload_gb<span style=color:#f92672>=</span>0, gpu_memory_utilization<span style=color:#f92672>=</span>0.9, num_gpu_blocks_override<span style=color:#f92672>=</span>None, max_num_batched_tokens<span style=color:#f92672>=</span>None, max_num_partial_prefills<span style=color:#f92672>=</span>1, max_long_partial_prefills<span style=color:#f92672>=</span>1, long_prefill_token_threshold<span style=color:#f92672>=</span>0, max_num_seqs<span style=color:#f92672>=</span>None, max_logprobs<span style=color:#f92672>=</span>20, disable_log_stats<span style=color:#f92672>=</span>False, quantization<span style=color:#f92672>=</span>None, rope_scaling<span style=color:#f92672>=</span>None, rope_theta<span style=color:#f92672>=</span>None, hf_overrides<span style=color:#f92672>=</span>None, enforce_eager<span style=color:#f92672>=</span>False, max_seq_len_to_capture<span style=color:#f92672>=</span>8192, disable_custom_all_reduce<span style=color:#f92672>=</span>False, tokenizer_pool_size<span style=color:#f92672>=</span>0, tokenizer_pool_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;ray&#39;</span>, tokenizer_pool_extra_config<span style=color:#f92672>=</span>None, limit_mm_per_prompt<span style=color:#f92672>=</span>None, mm_processor_kwargs<span style=color:#f92672>=</span>None, disable_mm_preprocessor_cache<span style=color:#f92672>=</span>False, enable_lora<span style=color:#f92672>=</span>False, enable_lora_bias<span style=color:#f92672>=</span>False, max_loras<span style=color:#f92672>=</span>1, max_lora_rank<span style=color:#f92672>=</span>16, lora_extra_vocab_size<span style=color:#f92672>=</span>256, lora_dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>, long_lora_scaling_factors<span style=color:#f92672>=</span>None, max_cpu_loras<span style=color:#f92672>=</span>None, fully_sharded_loras<span style=color:#f92672>=</span>False, enable_prompt_adapter<span style=color:#f92672>=</span>False, max_prompt_adapters<span style=color:#f92672>=</span>1, max_prompt_adapter_token<span style=color:#f92672>=</span>0, device<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>, num_scheduler_steps<span style=color:#f92672>=</span>1, use_tqdm_on_load<span style=color:#f92672>=</span>True, multi_step_stream_outputs<span style=color:#f92672>=</span>True, scheduler_delay_factor<span style=color:#f92672>=</span>0.0, enable_chunked_prefill<span style=color:#f92672>=</span>None, speculative_config<span style=color:#f92672>=</span>None, model_loader_extra_config<span style=color:#f92672>=</span>None, ignore_patterns<span style=color:#f92672>=[]</span>, preemption_mode<span style=color:#f92672>=</span>None, served_model_name<span style=color:#f92672>=</span>None, qlora_adapter_name_or_path<span style=color:#f92672>=</span>None, show_hidden_metrics_for_version<span style=color:#f92672>=</span>None, otlp_traces_endpoint<span style=color:#f92672>=</span>None, collect_detailed_traces<span style=color:#f92672>=</span>None, disable_async_output_proc<span style=color:#f92672>=</span>False, scheduling_policy<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;fcfs&#39;</span>, scheduler_cls<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;vllm.core.scheduler.Scheduler&#39;</span>, override_neuron_config<span style=color:#f92672>=</span>None, override_pooler_config<span style=color:#f92672>=</span>None, compilation_config<span style=color:#f92672>=</span>None, kv_transfer_config<span style=color:#f92672>=</span>None, worker_cls<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>, worker_extension_cls<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;&#39;</span>, generation_config<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>, override_generation_config<span style=color:#f92672>=</span>None, enable_sleep_mode<span style=color:#f92672>=</span>False, calculate_kv_scales<span style=color:#f92672>=</span>False, additional_config<span style=color:#f92672>=</span>None, enable_reasoning<span style=color:#f92672>=</span>False, reasoning_parser<span style=color:#f92672>=</span>None, disable_cascade_attn<span style=color:#f92672>=</span>False, disable_log_requests<span style=color:#f92672>=</span>False, max_log_len<span style=color:#f92672>=</span>None, disable_fastapi_docs<span style=color:#f92672>=</span>False, enable_prompt_tokens_details<span style=color:#f92672>=</span>False, enable_server_load_tracking<span style=color:#f92672>=</span>False, dispatch_function<span style=color:#f92672>=</span>&lt;<span style=color:#66d9ef>function</span> ServeSubcommand.cmd at 0x7f883404a7a0&gt;<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>INFO 04-14 06:01:01 <span style=color:#f92672>[</span>config.py:600<span style=color:#f92672>]</span> This model supports multiple tasks: <span style=color:#f92672>{</span><span style=color:#e6db74>&#39;score&#39;</span>, <span style=color:#e6db74>&#39;generate&#39;</span>, <span style=color:#e6db74>&#39;classify&#39;</span>, <span style=color:#e6db74>&#39;embed&#39;</span>, <span style=color:#e6db74>&#39;reward&#39;</span><span style=color:#f92672>}</span>. Defaulting to <span style=color:#e6db74>&#39;generate&#39;</span>.
</span></span><span style=display:flex><span>INFO 04-14 06:01:01 <span style=color:#f92672>[</span>config.py:1780<span style=color:#f92672>]</span> Chunked prefill is enabled with max_num_batched_tokens<span style=color:#f92672>=</span>2048.
</span></span><span style=display:flex><span>INFO 04-14 06:01:08 <span style=color:#f92672>[</span>__init__.py:239<span style=color:#f92672>]</span> Automatically detected platform cuda.
</span></span><span style=display:flex><span>INFO 04-14 06:01:11 <span style=color:#f92672>[</span>core.py:61<span style=color:#f92672>]</span> Initializing a V1 LLM engine <span style=color:#f92672>(</span>v0.8.3<span style=color:#f92672>)</span> with config: model<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;/data/DeepSeek-R1-Distill-Qwen-1.5B&#39;</span>, speculative_config<span style=color:#f92672>=</span>None, tokenizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;/data/DeepSeek-R1-Distill-Qwen-1.5B&#39;</span>, skip_tokenizer_init<span style=color:#f92672>=</span>False, tokenizer_mode<span style=color:#f92672>=</span>auto, revision<span style=color:#f92672>=</span>None, override_neuron_config<span style=color:#f92672>=</span>None, tokenizer_revision<span style=color:#f92672>=</span>None, trust_remote_code<span style=color:#f92672>=</span>False, dtype<span style=color:#f92672>=</span>torch.bfloat16, max_seq_len<span style=color:#f92672>=</span>131072, download_dir<span style=color:#f92672>=</span>None, load_format<span style=color:#f92672>=</span>auto, tensor_parallel_size<span style=color:#f92672>=</span>1, pipeline_parallel_size<span style=color:#f92672>=</span>1, disable_custom_all_reduce<span style=color:#f92672>=</span>False, quantization<span style=color:#f92672>=</span>None, enforce_eager<span style=color:#f92672>=</span>False, kv_cache_dtype<span style=color:#f92672>=</span>auto,  device_config<span style=color:#f92672>=</span>cuda, decoding_config<span style=color:#f92672>=</span>DecodingConfig<span style=color:#f92672>(</span>guided_decoding_backend<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;xgrammar&#39;</span>, reasoning_backend<span style=color:#f92672>=</span>None<span style=color:#f92672>)</span>, observability_config<span style=color:#f92672>=</span>ObservabilityConfig<span style=color:#f92672>(</span>show_hidden_metrics<span style=color:#f92672>=</span>False, otlp_traces_endpoint<span style=color:#f92672>=</span>None, collect_model_forward_time<span style=color:#f92672>=</span>False, collect_model_execute_time<span style=color:#f92672>=</span>False<span style=color:#f92672>)</span>, seed<span style=color:#f92672>=</span>None, served_model_name<span style=color:#f92672>=</span>/data/DeepSeek-R1-Distill-Qwen-1.5B, num_scheduler_steps<span style=color:#f92672>=</span>1, multi_step_stream_outputs<span style=color:#f92672>=</span>True, enable_prefix_caching<span style=color:#f92672>=</span>True, chunked_prefill_enabled<span style=color:#f92672>=</span>True, use_async_output_proc<span style=color:#f92672>=</span>True, disable_mm_preprocessor_cache<span style=color:#f92672>=</span>False, mm_processor_kwargs<span style=color:#f92672>=</span>None, pooler_config<span style=color:#f92672>=</span>None, compilation_config<span style=color:#f92672>={</span><span style=color:#e6db74>&#34;level&#34;</span>:3,<span style=color:#e6db74>&#34;custom_ops&#34;</span>:<span style=color:#f92672>[</span><span style=color:#e6db74>&#34;none&#34;</span><span style=color:#f92672>]</span>,<span style=color:#e6db74>&#34;splitting_ops&#34;</span>:<span style=color:#f92672>[</span><span style=color:#e6db74>&#34;vllm.unified_attention&#34;</span>,<span style=color:#e6db74>&#34;vllm.unified_attention_with_output&#34;</span><span style=color:#f92672>]</span>,<span style=color:#e6db74>&#34;use_inductor&#34;</span>:true,<span style=color:#e6db74>&#34;compile_sizes&#34;</span>:<span style=color:#f92672>[]</span>,<span style=color:#e6db74>&#34;use_cudagraph&#34;</span>:true,<span style=color:#e6db74>&#34;cudagraph_num_of_warmups&#34;</span>:1,<span style=color:#e6db74>&#34;cudagraph_capture_sizes&#34;</span>:<span style=color:#f92672>[</span>512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1<span style=color:#f92672>]</span>,<span style=color:#e6db74>&#34;max_capture_size&#34;</span>:512<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>WARNING 04-14 06:01:11 <span style=color:#f92672>[</span>utils.py:2413<span style=color:#f92672>]</span> Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in &lt;vllm.v1.worker.gpu_worker.Worker object at 0x7fd287cd4670&gt;
</span></span><span style=display:flex><span>INFO 04-14 06:01:12 <span style=color:#f92672>[</span>parallel_state.py:957<span style=color:#f92672>]</span> rank <span style=color:#ae81ff>0</span> in world size <span style=color:#ae81ff>1</span> is assigned as DP rank 0, PP rank 0, TP rank <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>INFO 04-14 06:01:12 <span style=color:#f92672>[</span>cuda.py:221<span style=color:#f92672>]</span> Using Flash Attention backend on V1 engine.
</span></span><span style=display:flex><span>INFO 04-14 06:01:12 <span style=color:#f92672>[</span>gpu_model_runner.py:1258<span style=color:#f92672>]</span> Starting to load model /data/DeepSeek-R1-Distill-Qwen-1.5B...
</span></span><span style=display:flex><span>WARNING 04-14 06:01:12 <span style=color:#f92672>[</span>topk_topp_sampler.py:69<span style=color:#f92672>]</span> FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p &amp; top-k sampling. For the best performance, please install FlashInfer.
</span></span><span style=display:flex><span>INFO 04-14 06:01:13 <span style=color:#f92672>[</span>loader.py:447<span style=color:#f92672>]</span> Loading weights took 0.95 seconds
</span></span><span style=display:flex><span>INFO 04-14 06:01:14 <span style=color:#f92672>[</span>gpu_model_runner.py:1273<span style=color:#f92672>]</span> Model loading took 3.3465 GiB and 1.192773 seconds
</span></span><span style=display:flex><span>INFO 04-14 06:01:23 <span style=color:#f92672>[</span>backends.py:416<span style=color:#f92672>]</span> Using cache directory: /root/.cache/vllm/torch_compile_cache/74d872966c/rank_0_0 <span style=color:#66d9ef>for</span> vLLM<span style=color:#e6db74>&#39;s torch.compile
</span></span></span><span style=display:flex><span><span style=color:#e6db74>INFO 04-14 06:01:23 [backends.py:426] Dynamo bytecode transform time: 9.12 s
</span></span></span><span style=display:flex><span><span style=color:#e6db74>INFO 04-14 06:01:26 [backends.py:132] Cache the graph of shape None for later use
</span></span></span><span style=display:flex><span><span style=color:#e6db74>INFO 04-14 06:01:54 [backends.py:144] Compiling a graph for general shape takes 30.65 s
</span></span></span><span style=display:flex><span><span style=color:#e6db74>INFO 04-14 06:02:03 [monitor.py:33] torch.compile takes 39.77 s in total
</span></span></span><span style=display:flex><span><span style=color:#e6db74>INFO 04-14 06:02:04 [kv_cache_utils.py:578] GPU KV cache size: 426,448 tokens
</span></span></span><span style=display:flex><span><span style=color:#e6db74>INFO 04-14 06:02:04 [kv_cache_utils.py:581] Maximum concurrency for 131,072 tokens per request: 3.25x
</span></span></span><span style=display:flex><span><span style=color:#e6db74>INFO 04-14 06:02:33 [gpu_model_runner.py:1608] Graph capturing finished in 29 secs, took 1.47 GiB
</span></span></span><span style=display:flex><span><span style=color:#e6db74>INFO 04-14 06:02:33 [core.py:162] init engine (profile, create kv cache, warmup model) took 79.67 seconds
</span></span></span><span style=display:flex><span><span style=color:#e6db74>WARNING 04-14 06:02:33 [config.py:1088] Default sampling parameters have been overridden by the model&#39;</span>s Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with <span style=color:#e6db74>`</span>--generation-config vllm<span style=color:#e6db74>`</span>.
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>serving_chat.py:117<span style=color:#f92672>]</span> Using default chat sampling params from model: <span style=color:#f92672>{</span><span style=color:#e6db74>&#39;temperature&#39;</span>: 0.6, <span style=color:#e6db74>&#39;top_p&#39;</span>: 0.95<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>serving_completion.py:61<span style=color:#f92672>]</span> Using default completion sampling params from model: <span style=color:#f92672>{</span><span style=color:#e6db74>&#39;temperature&#39;</span>: 0.6, <span style=color:#e6db74>&#39;top_p&#39;</span>: 0.95<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>api_server.py:1081<span style=color:#f92672>]</span> Starting vLLM API server on http://0.0.0.0:8000
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:26<span style=color:#f92672>]</span> Available routes are:
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /openapi.json, Methods: HEAD, GET
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /docs, Methods: HEAD, GET
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /docs/oauth2-redirect, Methods: HEAD, GET
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /redoc, Methods: HEAD, GET
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /health, Methods: GET
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /load, Methods: GET
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /ping, Methods: GET, POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /tokenize, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /detokenize, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /v1/models, Methods: GET
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /version, Methods: GET
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /v1/chat/completions, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /v1/completions, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /v1/embeddings, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /pooling, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /score, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /v1/score, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /v1/audio/transcriptions, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /rerank, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /v1/rerank, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /v2/rerank, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:33 <span style=color:#f92672>[</span>launcher.py:34<span style=color:#f92672>]</span> Route: /invocations, Methods: POST
</span></span><span style=display:flex><span>INFO 04-14 06:02:44 <span style=color:#f92672>[</span>loggers.py:87<span style=color:#f92672>]</span> Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: <span style=color:#ae81ff>0</span> reqs, Waiting: <span style=color:#ae81ff>0</span> reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
</span></span><span style=display:flex><span>INFO 04-14 06:02:54 <span style=color:#f92672>[</span>loggers.py:87<span style=color:#f92672>]</span> Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: <span style=color:#ae81ff>0</span> reqs, Waiting: <span style=color:#ae81ff>0</span> reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
</span></span><span style=display:flex><span>INFO 04-14 06:03:04 <span style=color:#f92672>[</span>loggers.py:87<span style=color:#f92672>]</span> Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: <span style=color:#ae81ff>0</span> reqs, Waiting: <span style=color:#ae81ff>0</span> reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
</span></span><span style=display:flex><span>INFO 04-14 06:03:14 <span style=color:#f92672>[</span>loggers.py:87<span style=color:#f92672>]</span> Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: <span style=color:#ae81ff>0</span> reqs, Waiting: <span style=color:#ae81ff>0</span> reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
</span></span><span style=display:flex><span>INFO 04-14 06:03:24 <span style=color:#f92672>[</span>loggers.py:87<span style=color:#f92672>]</span> Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: <span style=color:#ae81ff>0</span> reqs, Waiting: <span style=color:#ae81ff>0</span> reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
</span></span><span style=display:flex><span>INFO 04-14 06:03:34 <span style=color:#f92672>[</span>loggers.py:87<span style=color:#f92672>]</span> Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: <span style=color:#ae81ff>0</span> reqs, Waiting: <span style=color:#ae81ff>0</span> reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
</span></span><span style=display:flex><span>INFO 04-14 06:03:44 <span style=color:#f92672>[</span>loggers.py:87<span style=color:#f92672>]</span> Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: <span style=color:#ae81ff>0</span> reqs, Waiting: <span style=color:#ae81ff>0</span> reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
</span></span><span style=display:flex><span>INFO 04-14 06:03:54 <span style=color:#f92672>[</span>loggers.py:87<span style=color:#f92672>]</span> Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: <span style=color:#ae81ff>0</span> reqs, Waiting: <span style=color:#ae81ff>0</span> reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
</span></span><span style=display:flex><span>INFO 04-14 06:04:04 <span style=color:#f92672>[</span>loggers.py:87<span style=color:#f92672>]</span> Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: <span style=color:#ae81ff>0</span> reqs, Waiting: <span style=color:#ae81ff>0</span> reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
</span></span><span style=display:flex><span>INFO 04-14 06:04:12 <span style=color:#f92672>[</span>launcher.py:74<span style=color:#f92672>]</span> Shutting down FastAPI HTTP server.
</span></span><span style=display:flex><span>INFO 04-14 06:04:14 <span style=color:#f92672>[</span>loggers.py:87<span style=color:#f92672>]</span> Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: <span style=color:#ae81ff>0</span> reqs, Waiting: <span style=color:#ae81ff>0</span> reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
</span></span></code></pre></td></tr></table></div></div><hr><h2 id=32-æ¨¡å‹é…ç½®>3.2 æ¨¡å‹é…ç½®<a hidden class=anchor aria-hidden=true href=#32-æ¨¡å‹é…ç½®>#</a></h2><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;architectures&#34;</span>: <span style=color:#f92672>[</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;Qwen2ForCausalLM&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;attention_dropout&#34;</span>: 0.0,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;bos_token_id&#34;</span>: 151643,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;eos_token_id&#34;</span>: 151643,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;hidden_act&#34;</span>: <span style=color:#e6db74>&#34;silu&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;hidden_size&#34;</span>: 1536,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;initializer_range&#34;</span>: 0.02,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;intermediate_size&#34;</span>: 8960,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;max_position_embeddings&#34;</span>: 131072,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;max_window_layers&#34;</span>: 21,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;model_type&#34;</span>: <span style=color:#e6db74>&#34;qwen2&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;num_attention_heads&#34;</span>: 12,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;num_hidden_layers&#34;</span>: 28,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;num_key_value_heads&#34;</span>: 2,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;rms_norm_eps&#34;</span>: 1e-06,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;rope_theta&#34;</span>: 10000,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;sliding_window&#34;</span>: 4096,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;tie_word_embeddings&#34;</span>: false,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;torch_dtype&#34;</span>: <span style=color:#e6db74>&#34;bfloat16&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;transformers_version&#34;</span>: <span style=color:#e6db74>&#34;4.44.0&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;use_cache&#34;</span>: true,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;use_mrope&#34;</span>: false,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;use_sliding_window&#34;</span>: false,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;vocab_size&#34;</span>: <span style=color:#ae81ff>151936</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span></code></pre></td></tr></table></div></div><hr><h2 id=33-è®¡ç®—éªŒè¯>3.3 è®¡ç®—éªŒè¯<a hidden class=anchor aria-hidden=true href=#33-è®¡ç®—éªŒè¯>#</a></h2><h3 id=331-æ¯ä¸ªtokençš„kvç¼“å­˜å¤§å°è®¡ç®—>3.3.1 æ¯ä¸ªtokençš„KVç¼“å­˜å¤§å°è®¡ç®—<a hidden class=anchor aria-hidden=true href=#331-æ¯ä¸ªtokençš„kvç¼“å­˜å¤§å°è®¡ç®—>#</a></h3><ul><li>head_size = hidden_size / num_attention_heads = 1536 / 12 = 128</li><li>å•tokenå•å±‚çš„KVç¼“å­˜ = 2(Kå’ŒV) * num_key_value_heads * head_size * dtype = 2 * 2 * 128 * 2 = 1024å­—èŠ‚</li><li>å…¨æ¨¡å‹å•token KVç¼“å­˜ = å•tokenå•å±‚çš„KVç¼“å­˜ * num_hidden_layers = 1024 * 28 = 28672å­—èŠ‚</li></ul><hr><h3 id=332-æ˜¾å­˜åˆ†é…>3.3.2 æ˜¾å­˜åˆ†é…<a hidden class=anchor aria-hidden=true href=#332-æ˜¾å­˜åˆ†é…>#</a></h3><ul><li>æ€»å¯ç”¨æ˜¾å­˜ = 24GB * 0.9 = 21.6GB</li><li>éƒ¨åˆ†æ˜¾å­˜ç”¨äºæ¨¡å‹æƒé‡ã€æ¿€æ´»å€¼ç­‰</li><li>å‰©ä½™æ˜¾å­˜ç”¨äºKVç¼“å­˜</li></ul><hr><h3 id=333-å¯ç¼“å­˜çš„tokenæ•°é‡>3.3.3 å¯ç¼“å­˜çš„tokenæ•°é‡<a hidden class=anchor aria-hidden=true href=#333-å¯ç¼“å­˜çš„tokenæ•°é‡>#</a></h3><p>æ—¥å¿—çš„ç»“æœä¸ºï¼šINFO 04-14 06:02:04 [kv_cache_utils.py:578] GPU KV cache size: 426,448 tokens</p><ul><li>æ ¹æ®æ—¥å¿—ç»“æœåæ¨å¯å¾—åˆ°ï¼šå‰©ä½™æ˜¾å­˜ç”¨äºKVç¼“å­˜ / æ¯ä¸ªtokençš„KVç¼“å­˜å¤§å° = 426448</li><li>å‰©ä½™æ˜¾å­˜ç”¨äºKVç¼“å­˜å¤§å°ä¸ºï¼š11.38739 GB</li></ul><hr><h1 id=4-vllmä¸­å¦‚ä½•è®¡ç®—kvcache>4. vLLMä¸­å¦‚ä½•è®¡ç®—KVcache<a hidden class=anchor aria-hidden=true href=#4-vllmä¸­å¦‚ä½•è®¡ç®—kvcache>#</a></h1><p>æ¥ä¸Šä¸€èŠ‚ï¼Œä»vLLMä»£ç å±‚é¢åˆ†æï¼Œ426,448ä¸ªtokençš„KVç¼“å­˜å®¹é‡æ˜¯é€šè¿‡ä»¥ä¸‹æ­¥éª¤è®¡ç®—å¾—å‡ºçš„ï¼š</p><h2 id=41-æ ¸å¿ƒè®¡ç®—å‡½æ•°>4.1 æ ¸å¿ƒè®¡ç®—å‡½æ•°<a hidden class=anchor aria-hidden=true href=#41-æ ¸å¿ƒè®¡ç®—å‡½æ•°>#</a></h2><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>worker.py: determine_num_available_blocks<span style=color:#f92672>()</span> â†’ è®¡ç®—å¯ç”¨å—æ•°é‡
</span></span><span style=display:flex><span>cache_engine.py: get_cache_block_size<span style=color:#f92672>()</span> â†’ è®¡ç®—æ¯ä¸ªå—å¤§å°
</span></span><span style=display:flex><span>kv_cache_utils.py: get_kv_cache_configs<span style=color:#f92672>()</span> â†’ é…ç½®KVç¼“å­˜
</span></span></code></pre></td></tr></table></div></div><h2 id=411-determine_num_available_blocks>4.1.1 determine_num_available_blocks()<a hidden class=anchor aria-hidden=true href=#411-determine_num_available_blocks>#</a></h2><p>å¯¹äºä½ çš„4090D(24GB)ï¼Œä½¿ç”¨0.9çš„gpu_memory_utilizationï¼š</p><ul><li>æ€»æ˜¾å­˜: 24GBÂ Ã— 0.9Â â‰ˆ 21.6GB</li><li>å‡å»æ¨¡å‹æƒé‡å’Œæ¿€æ´»å€¼ç­‰éKVç¼“å­˜éƒ¨åˆ†</li></ul><hr><h2 id=412-get_cache_blockz_size>4.1.2 get_cache_blockZ_size()<a hidden class=anchor aria-hidden=true href=#412-get_cache_blockz_size>#</a></h2><blockquote><p>ğŸ’¡ è®¡ç®—ç¼“å­˜å—çš„å¤§å°</p></blockquote><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#a6e22e>@staticmethod</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_cache_block_size</span>(cache_config, model_config, parallel_config):
</span></span><span style=display:flex><span>    head_size <span style=color:#f92672>=</span> model_config<span style=color:#f92672>.</span>get_head_size()  <span style=color:#75715e># 128</span>
</span></span><span style=display:flex><span>    num_heads <span style=color:#f92672>=</span> model_config<span style=color:#f92672>.</span>get_num_kv_heads(parallel_config)  <span style=color:#75715e># 2</span>
</span></span><span style=display:flex><span>    num_attention_layers <span style=color:#f92672>=</span> model_config<span style=color:#f92672>.</span>get_num_layers_by_block_type(
</span></span><span style=display:flex><span>        parallel_config, LayerBlockType<span style=color:#f92672>.</span>attention)  <span style=color:#75715e># 28</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># è·å–æ•°æ®ç±»å‹å¤§å°</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> cache_config<span style=color:#f92672>.</span>cache_dtype <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;auto&#34;</span>:
</span></span><span style=display:flex><span>        dtype <span style=color:#f92672>=</span> model_config<span style=color:#f92672>.</span>dtype  <span style=color:#75715e># bfloat16</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        dtype <span style=color:#f92672>=</span> STR_DTYPE_TO_TORCH_DTYPE[cache_config<span style=color:#f92672>.</span>cache_dtype]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># è®¡ç®—keyç¼“å­˜é¡¹å’Œvalueç¼“å­˜é¡¹å¤§å°</span>
</span></span><span style=display:flex><span>    key_cache_entry <span style=color:#f92672>=</span> num_heads <span style=color:#f92672>*</span> head_size  <span style=color:#75715e># 2 * 128 = 256</span>
</span></span><span style=display:flex><span>    value_cache_entry <span style=color:#f92672>=</span> key_cache_entry  <span style=color:#75715e># 256</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># è®¡ç®—ä¸€ä¸ªå—çš„æ€»å…ƒç´ æ•°</span>
</span></span><span style=display:flex><span>    total <span style=color:#f92672>=</span> num_attention_layers <span style=color:#f92672>*</span> cache_config<span style=color:#f92672>.</span>block_size <span style=color:#f92672>*</span> (key_cache_entry <span style=color:#f92672>+</span> value_cache_entry)
</span></span><span style=display:flex><span>    <span style=color:#75715e># 28 * 16 * (256 + 256) = 28 * 16 * 512 = 229,376ä¸ªå…ƒç´ </span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># æ¯ä¸ªå…ƒç´ çš„å­—èŠ‚å¤§å°(bfloat16 = 2å­—èŠ‚)</span>
</span></span><span style=display:flex><span>    dtype_size <span style=color:#f92672>=</span> get_dtype_size(dtype)  <span style=color:#75715e># 2</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># è¿”å›å—å¤§å°(å­—èŠ‚)</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> dtype_size <span style=color:#f92672>*</span> total  <span style=color:#75715e># 2 * 229,376 = 458,752å­—èŠ‚</span>
</span></span></code></pre></td></tr></table></div></div><hr><h2 id=413-determine_num_available_blocks>4.1.3 determine_num_available_blocks()<a hidden class=anchor aria-hidden=true href=#413-determine_num_available_blocks>#</a></h2><blockquote><p>ğŸ’¡ è®¡ç®—å¯ç”¨å—çš„æ•°é‡</p></blockquote><p>é‡æ–°å›åˆ°determine_num_available_blocks()</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>cache_block_size <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>get_cache_block_size_bytes()
</span></span><span style=display:flex><span>num_gpu_blocks <span style=color:#f92672>=</span> int(available_kv_cache_memory <span style=color:#f92672>//</span> cache_block_size)
</span></span></code></pre></td></tr></table></div></div><p>è¿™é‡Œclaude-3.7-sonnetå›å¤ç»“æœä¸ºï¼š</p><p>è®¡ç®—å¯ç”¨å—æ•°ï¼š</p><ul><li>å‡è®¾å¯ç”¨äºKVç¼“å­˜çš„æ˜¾å­˜çº¦ä¸º12.2GB</li><li>æ¯ä¸ªå—å¤§å°ä¸º458.75KB</li><li>å—æ•°é‡Â = 12.2GBÂ Ã· 458.75KBÂ â‰ˆ 26,653å—
æˆ‘è§‰å¾—12.2GBä¸æ˜¯å¾ˆä¸¥è°¨ï¼Œä¸“é—¨å»æŸ¥äº†ä¸€ä¸‹å¦‚ä½•ä¼°ç®—å‡º12.2GBçš„è¿‡ç¨‹ã€‚ä»£å…¥qwen1.5bæ¨¡å‹ï¼Œæ¨èåœºæ™¯ä¸‹ä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œæ‰€ä»¥äº§ç”Ÿçš„æ˜¾å­˜ç±»å‹åº”è¯¥ä¸ºï¼šæ¨¡å‹æƒé‡å’Œå‰ä¼ çš„æ¿€æ´»å€¼ã€‚æ¨¡å‹æƒé‡çš„è®¡ç®—ï¼šå‚æ•°é‡ * dtype â‰ˆ 3GBï¼Œå‰ä¼ çš„æ¿€æ´»å€¼ï¼Œæ²¡æŸ¥åˆ°æ¥æºä¾æ®ã€‚</li></ul><hr><h2 id=414-_get_kv_cache_config_uniform_type>4.1.4 _get_kv_cache_config_uniform_type()<a hidden class=anchor aria-hidden=true href=#414-_get_kv_cache_config_uniform_type>#</a></h2><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">64
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_get_kv_cache_config_uniform_type</span>(vllm_config: VllmConfig,
</span></span><span style=display:flex><span>                                      kv_cache_spec: KVCacheSpec,
</span></span><span style=display:flex><span>                                      available_memory: int,
</span></span><span style=display:flex><span>                                      num_layers: int) <span style=color:#f92672>-&gt;</span> KVCacheConfig:
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    ä¸ºå…·æœ‰å•ä¸€ç±»å‹KVç¼“å­˜çš„æ¨¡å‹ç”ŸæˆKVç¼“å­˜é…ç½®ã€‚
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    å°†å¯ç”¨å†…å­˜å¹³å‡åˆ†é…ç»™æ‰€æœ‰å±‚ã€‚
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    å‚æ•°:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        vllm_config: å…¨å±€VllmConfigé…ç½®
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        kv_cache_spec: æ¨¡å‹çš„KVç¼“å­˜è§„æ ¼
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        available_memory: KVç¼“å­˜å¯ç”¨çš„å†…å­˜å¤§å°(å­—èŠ‚)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        num_layers: æ¨¡å‹çš„å±‚æ•°
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    è¿”å›:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        ç”Ÿæˆçš„KVCacheConfigé…ç½®
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># è·å–æ‰€æœ‰å±‚çš„é¡µé¢å¤§å°(å­—èŠ‚)</span>
</span></span><span style=display:flex><span>    page_sizes <span style=color:#f92672>=</span> {layer<span style=color:#f92672>.</span>page_size_bytes <span style=color:#66d9ef>for</span> layer <span style=color:#f92672>in</span> kv_cache_spec<span style=color:#f92672>.</span>values()}
</span></span><span style=display:flex><span>    <span style=color:#75715e># ç¡®ä¿æ‰€æœ‰å±‚ä½¿ç”¨ç›¸åŒçš„é¡µé¢å¤§å°</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>assert</span> len(page_sizes) <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    page_size <span style=color:#f92672>=</span> page_sizes<span style=color:#f92672>.</span>pop()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># è®¡ç®—æ¯å±‚å¯åˆ†é…çš„å—æ•°</span>
</span></span><span style=display:flex><span>    num_blocks <span style=color:#f92672>=</span> int(available_memory <span style=color:#f92672>//</span> page_size <span style=color:#f92672>//</span> num_layers)
</span></span><span style=display:flex><span>    num_blocks <span style=color:#f92672>=</span> max(num_blocks, <span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># å¦‚æœé…ç½®ä¸­æŒ‡å®šäº†GPUå—æ•°çš„è¦†ç›–å€¼,åˆ™ä½¿ç”¨è¯¥å€¼</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> vllm_config<span style=color:#f92672>.</span>cache_config<span style=color:#f92672>.</span>num_gpu_blocks_override <span style=color:#f92672>is</span> <span style=color:#f92672>not</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        num_gpu_blocks_override <span style=color:#f92672>=</span> \
</span></span><span style=display:flex><span>            vllm_config<span style=color:#f92672>.</span>cache_config<span style=color:#f92672>.</span>num_gpu_blocks_override
</span></span><span style=display:flex><span>        logger<span style=color:#f92672>.</span>info(
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;ä½¿ç”¨num_gpu_blocks_override=</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>è¦†ç›–åŸå§‹num_gpu_blocks=</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>&#34;</span>,
</span></span><span style=display:flex><span>            num_gpu_blocks_override, num_blocks)
</span></span><span style=display:flex><span>        num_blocks <span style=color:#f92672>=</span> num_gpu_blocks_override
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># è®°å½•GPUå—æ•°ä¿¡æ¯</span>
</span></span><span style=display:flex><span>    logger<span style=color:#f92672>.</span>info(<span style=color:#e6db74>&#34;GPUå—æ•°: </span><span style=color:#e6db74>%d</span><span style=color:#e6db74>&#34;</span>, num_blocks)
</span></span><span style=display:flex><span>    <span style=color:#75715e># è®¡ç®—æœ€å¤§å¹¶å‘åº¦</span>
</span></span><span style=display:flex><span>    max_concurrency <span style=color:#f92672>=</span> (num_blocks <span style=color:#f92672>*</span> vllm_config<span style=color:#f92672>.</span>cache_config<span style=color:#f92672>.</span>block_size <span style=color:#f92672>/</span>
</span></span><span style=display:flex><span>                       vllm_config<span style=color:#f92672>.</span>model_config<span style=color:#f92672>.</span>max_model_len)
</span></span><span style=display:flex><span>    logger<span style=color:#f92672>.</span>info(<span style=color:#e6db74>&#34;æ¯ä¸ªè¯·æ±‚</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>ä¸ªtokenæ—¶çš„æœ€å¤§å¹¶å‘åº¦: </span><span style=color:#e6db74>%.2f</span><span style=color:#e6db74>x&#34;</span>,
</span></span><span style=display:flex><span>                vllm_config<span style=color:#f92672>.</span>model_config<span style=color:#f92672>.</span>max_model_len, max_concurrency)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># è®¡ç®—æ¯å±‚çš„å†…å­˜å¤§å°</span>
</span></span><span style=display:flex><span>    per_layer_size <span style=color:#f92672>=</span> page_size <span style=color:#f92672>*</span> num_blocks
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># åˆ›å»ºKVç¼“å­˜é…ç½®</span>
</span></span><span style=display:flex><span>    kv_cache_config <span style=color:#f92672>=</span> KVCacheConfig(
</span></span><span style=display:flex><span>        num_blocks<span style=color:#f92672>=</span>num_blocks,
</span></span><span style=display:flex><span>        <span style=color:#75715e># ä¸ºæ¯ä¸€å±‚åˆ›å»ºç›¸åŒå¤§å°çš„KVç¼“å­˜å¼ é‡</span>
</span></span><span style=display:flex><span>        tensors<span style=color:#f92672>=</span>{
</span></span><span style=display:flex><span>            layer_name: KVCacheTensor(size<span style=color:#f92672>=</span>per_layer_size)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> layer_name <span style=color:#f92672>in</span> kv_cache_spec
</span></span><span style=display:flex><span>        },
</span></span><span style=display:flex><span>        <span style=color:#75715e># å°†æ‰€æœ‰å±‚ç»„ç»‡ä¸ºä¸€ä¸ªç»„</span>
</span></span><span style=display:flex><span>        groups<span style=color:#f92672>=</span>[[layer_name <span style=color:#66d9ef>for</span> layer_name <span style=color:#f92672>in</span> kv_cache_spec]],
</span></span><span style=display:flex><span>        kv_cache_spec<span style=color:#f92672>=</span>kv_cache_spec)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> kv_cache_config
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#75715e># æ€»tokenå®¹é‡ = å—æ•°é‡ * æ¯å—å­˜å‚¨çš„tokenæ•°</span>
</span></span><span style=display:flex><span>total_tokens <span style=color:#f92672>=</span> num_gpu_blocks <span style=color:#f92672>*</span> block_size
</span></span><span style=display:flex><span>logger<span style=color:#f92672>.</span>info(<span style=color:#e6db74>&#34;GPU KV cache size: </span><span style=color:#e6db74>%d</span><span style=color:#e6db74> tokens&#34;</span>, total_tokens)
</span></span></code></pre></td></tr></table></div></div><p>æ€»tokenå®¹é‡ = 26653 * 16 = 426448ï¼Œ ä¸æ—¥å¿—å¯¹æ¯”å‘ç°æ•°å€¼ä¸€è‡´ã€‚</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://Pan-Binghong.github.io/daily-learning/tags/vllm/>VLLM</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://Pan-Binghong.github.io/daily-learning/>æˆ‘çš„åšå®¢</a></span> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>